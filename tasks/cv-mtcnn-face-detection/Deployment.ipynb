{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   MTCNN Face Detection - Implantação\n",
    "\n",
    "*   Este componente utiliza a biblioteca [facenet-pytorch](https://github.com/timesler/facenet-pytorch), a qual disponibiliza o algorítimo [MTCNN](https://arxiv.org/abs/1604.02878). \n",
    "\n",
    "* O MTCNN possui a performance estado da arte nos benchmarks [FDDB](http://vis-www.cs.umass.edu/fddb/) e [WIDER FACE](http://shuoyang1213.me/WIDERFACE/)\n",
    "\n",
    "*   Melhores explicações são encontradas neste [artigo do kaggle](https://www.kaggle.com/timesler/guide-to-mtcnn-in-facenet-pytorch)\n",
    "\n",
    "\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de Classe para Predições em Tempo Real\n",
    "\n",
    "A tarefa de implantação cria um serviço REST para predições em tempo-real.<br>\n",
    "Para isso você deve criar uma classe `Model` que implementa o método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install facenet-pytorch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Model.py\n",
    "import joblib\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import cv2\n",
    "from mtcnn import MTCNN_Model\n",
    "\n",
    "        \n",
    "class Model(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        artifacts = joblib.load(\"/tmp/data/mtcnn.joblib\")\n",
    "        self.model_parameters = artifacts[\"model_parameters\"]\n",
    "        self.inference_parameters = artifacts[\"inference_parameters\"]\n",
    "        \n",
    "    def class_names(self):\n",
    "        \n",
    "        return ['bboxcoord1', 'bboxcoord2', 'bboxcoord3', 'bboxcoord4', 'probability']\n",
    "        \n",
    "    def format_result(self, bboxes, probs):\n",
    "        \n",
    "        res = []\n",
    "        \n",
    "        for bbox_id, prob in enumerate(probs):\n",
    "            \n",
    "            # Check if has found a bbox for the image\n",
    "            if prob is None:\n",
    "                bbox = [None, None, None, None, None]\n",
    "            \n",
    "            # Extend to an array the 4coords and prob\n",
    "            else:\n",
    "                bbox = list(map(float, bboxes[bbox_id]))\n",
    "                bbox.extend([float(probs[bbox_id])])\n",
    "                \n",
    "            res.append(bbox)\n",
    "        \n",
    "        return np.array(res)\n",
    "    \n",
    "    def predict(self, X, feature_names, meta=None):\n",
    "        \n",
    "        # Check if data is a bytes\n",
    "        if isinstance(X, bytes):\n",
    "            im_bytes = X # Get image bytes\n",
    "        \n",
    "        # If not, should be a list or ndarray\n",
    "        else:\n",
    "            # Garantee is a ndarray\n",
    "            X = np.array(X)\n",
    "            \n",
    "            # Seek for extra dimension\n",
    "            if len(X.shape) == 2:\n",
    "                im_bytes = X[0,0] # Get image bytes\n",
    "            \n",
    "            else:\n",
    "                im_bytes = X[0] # Get image bytes\n",
    "        \n",
    "        # Preprocess img bytes to img_arr\n",
    "        im_arr = np.frombuffer(im_bytes, dtype=np.uint8)\n",
    "        img = cv2.imdecode(im_arr, flags=cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        img_arr = np.array(img)\n",
    "        \n",
    "        # Initializate model\n",
    "        model = MTCNN_Model(self.model_parameters, self.inference_parameters)\n",
    "        \n",
    "        # Predict results\n",
    "        bboxes, probs = model.predict(img_arr)\n",
    "        \n",
    "        # Remove batch dimension\n",
    "        bboxes, probs = np.squeeze(bboxes, 0), np.squeeze(probs, 0)\n",
    "        \n",
    "#         ### DEBUG ###\n",
    "#         print('--- DBG ---')\n",
    "#         print('bboxes:', bboxes)\n",
    "#         print('--- DBG ---')\n",
    "#         print('probs:', probs)\n",
    "#         print('--- DBG ---')\n",
    "#         #############\n",
    "        \n",
    "        # Compile results\n",
    "        result = self.format_result(bboxes, probs)\n",
    "        \n",
    "#         ### DEBUG ###\n",
    "#         print('--- DBG ---')\n",
    "#         print('result:', result)\n",
    "#         print('--- DBG ---')\n",
    "#         #############\n",
    "\n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "afdb93d5-745d-4b2a-9cd4-6f6cafbcd70a",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "operator_id": "be6e00b0-f731-4b51-a1b4-3d927829a32d",
  "task_id": "e52d6cd0-977e-4441-91a6-f213457953d5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
