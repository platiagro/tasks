{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever - Implantação\n",
    "\n",
    "O objetivo deste componente é elencar a probabilidade de um conjunto de contextos conter a resposta a uma dada pergunta.\n",
    "\n",
    "Este componente utiliza diferentes modelos de similaridade entre textos para a sua inferência.<br>\n",
    "\n",
    "A tabela de dados de entrada deve possuir uma coluna de contextos, em que cada linha representa um contexto diferente, e uma coluna de perguntas em que cada linha representa uma pergunta a ser utilizada. Note que para cada pergunta serão utilizados todos os contextos fornecidos para realização da inferência, e portanto, podem haver bem mais contextos do que perguntas.<br>\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de Classe para Predições em Tempo Real\n",
    "\n",
    "A tarefa de implantação cria um serviço REST para predições em tempo-real.<br>\n",
    "Para isso você deve criar uma classe `Model` que implementa o método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download pt_core_news_lg --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Model.py\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from retriever import Retriever, MODEL_MAPPING\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.loaded = False\n",
    "\n",
    "    def load(self):\n",
    "        \n",
    "        # Load artifacts\n",
    "        artifacts = joblib.load(\"/tmp/data/retriever.joblib\")\n",
    "        self.model_parameters = artifacts[\"model_parameters\"]\n",
    "        self.inference_parameters = artifacts[\"inference_parameters\"]\n",
    "        \n",
    "        # Initialize retriever\n",
    "        self.sim_model = MODEL_MAPPING[self.inference_parameters['similarity_model']](**self.model_parameters)\n",
    "        self.retriever = Retriever(similarity_model=self.sim_model, **self.model_parameters)\n",
    "        \n",
    "        # Set model loaded\n",
    "        self.loaded = True\n",
    "        print(\"Loaded model\")\n",
    "    \n",
    "    def class_names(self):\n",
    "        column_names = list(self.inference_parameters['output_columns'])\n",
    "        return column_names\n",
    "\n",
    "    def predict(self, X, feature_names, meta=None):\n",
    "        if not self.loaded:\n",
    "            self.load()\n",
    "            \n",
    "        # Convert to dataframe\n",
    "        if feature_names != []:\n",
    "            df = pd.DataFrame(X, columns = feature_names)\n",
    "            df = df[self.inference_parameters['input_columns']]\n",
    "        else:\n",
    "            df = pd.DataFrame(X, columns = self.inference_parameters['input_columns'])\n",
    "            \n",
    "        # Get unique questions\n",
    "        unique_questions = list(df[self.inference_parameters['question_column_name']].unique())\n",
    "\n",
    "        # Initialize output df\n",
    "        output_df = pd.DataFrame(columns=self.inference_parameters['output_columns'])\n",
    "\n",
    "        # Iterate over each unique question\n",
    "        for question in unique_questions:\n",
    "\n",
    "            # Filter df per question\n",
    "            question_df = df[df[self.inference_parameters['question_column_name']] == question]\n",
    "\n",
    "            # Get Contexts\n",
    "            contexts = list(question_df[self.inference_parameters['context_column_name']])\n",
    "\n",
    "            # Get indices\n",
    "            context_ids = list(question_df.index)\n",
    "\n",
    "            # Retrieve contexts\n",
    "            topn_ids, topn_scores = self.retriever.retrieve_top(contexts, question, topn=self.inference_parameters['topn'], context_ids=context_ids)\n",
    "\n",
    "            # Retrieved df\n",
    "            retrieved_df = df.loc[topn_ids]\n",
    "            retrieved_df.at[topn_ids, self.inference_parameters['proba_column_name']] = topn_scores\n",
    "\n",
    "            # Save to output\n",
    "            output_df = pd.concat((output_df, retrieved_df)).reset_index(drop=True)\n",
    "        \n",
    "        return output_df.to_numpy()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "fbb8236f-0904-4b10-a3e4-114e475a5947",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "operator_id": "c740820e-ef3b-40dc-81a7-75f12ecb448c",
  "task_id": "b565bc02-738f-4624-abf9-6a4c52028a60"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
