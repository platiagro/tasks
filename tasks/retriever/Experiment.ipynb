{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever - Experimento\n",
    "\n",
    "O objetivo deste componente é elencar a probabilidade de um conjunto de contextos conter a resposta a uma dada pergunta.\n",
    "\n",
    "Este componente utiliza diferentes modelos de similaridade entre textos para a sua inferência.<br>\n",
    "\n",
    "A tabela de dados de entrada deve possuir uma coluna de contextos, em que cada linha representa um contexto diferente, e uma coluna de perguntas em que cada linha representa uma pergunta a ser utilizada. Note que para cada pergunta serão utilizados todos os contextos fornecidos para realização da inferência, e portanto, podem haver bem mais contextos do que perguntas.\n",
    "\n",
    "Obs: Este componente utiliza recursos da internet, portanto é importante estar conectado à rede para que este componente funcione corretamente.<br>\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "A variável `dataset` possui o caminho para leitura do arquivos importados na tarefa de \"Upload de dados\".<br>\n",
    "Você também pode importar arquivos com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"/tmp/data/simple_q&a-18.csv\" #@param {type:\"string\"}\n",
    "context_column_name = \"text\" #@param {type:\"string\", label:\"Coluna dos contextos\", description:\"Esta coluna será utilizada para ler os contextos e aplicar o Retriever.\"}\n",
    "question_column_name = \"question\" #@param {type:\"string\", label:\"Coluna das perguntas\", description:\"Esta coluna será utilizada para identificar as perguntas a serem aplicadas aos contextos.\"}\n",
    "topn = 2 #@param {type:\"number\",label:\"Top N contextos\",description:\"O número máximo de contextos para elencar por pergunta. Os contextos elencados correspondem aos que obtiveram melhor pontuação do Retriever.\"}\n",
    "similarity_model = \"paraphrase_multilingual\" #@param [\"paraphrase_multilingual\",\"bm25\",\"tf_idf\",\"word2vec\"] {type:\"string\",multiple:false,label:\"Modelo do Retriever\",description:\"Modelo para a inferência do Retriever.\"}\n",
    "proba_column_name = \"retriever_score\" #@param {type:\"string\", label:\"Coluna da pontuação das respostas\", description:\"Esta coluna será utilizada para salvar a pontuação dos N contextos selecionados de cada pergunta.\"}\n",
    "expected_column_name = \"\" #@param {type:\"string\", label:\"Coluna de avaliação\", description:\"Esta coluna será utilizada para avaliar as respostas produzidas por cada pergunta, deve conter a indicação do contexto esperado para o Retriever. É uma coluna opcional, mas caso preenchido deve ser também preenchida uma coluna de identificação dos contextos.\"}\n",
    "identifier_column_name = \"\" #@param {type:\"string\", label:\"Coluna de identidicação dos Contextos\", description:\"Esta coluna será utilizada para identificar os contextos caso seja informado uma coluna de avaliação.\"}\n",
    "device = \"cpu\" #@param [\"cuda\",\"cpu\"] {type:\"string\",multiple:false,label:\"Dispositivo\",description:\"Tipo de dispositivo para utilizar o componente.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura do conjunto de dados\n",
    "\n",
    "O exemplo abaixo faz a leitura de dados tabulares (ex: .csv).<br>\n",
    "Modifique o código de acordo com o tipo de dado que desejar ler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>expected_retriever_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A bola é um objeto utilizado para lazer de uma...</td>\n",
       "      <td>Qual o formato da bola?</td>\n",
       "      <td>esférica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Golfe é um esporte no qual os jogadores usam d...</td>\n",
       "      <td>Qual o formato da bola?</td>\n",
       "      <td>esférica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jogo por tacadas[1] (stroke play[2]), também c...</td>\n",
       "      <td>Qual o formato da bola?</td>\n",
       "      <td>esférica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A bola é um objeto utilizado para lazer de uma...</td>\n",
       "      <td>Aonde se pratica golfe?</td>\n",
       "      <td>campo de golfe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Golfe é um esporte no qual os jogadores usam d...</td>\n",
       "      <td>Aonde se pratica golfe?</td>\n",
       "      <td>campo de golfe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Jogo por tacadas[1] (stroke play[2]), também c...</td>\n",
       "      <td>Aonde se pratica golfe?</td>\n",
       "      <td>campo de golfe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  \\\n",
       "0      1  A bola é um objeto utilizado para lazer de uma...   \n",
       "1      2  Golfe é um esporte no qual os jogadores usam d...   \n",
       "2      3  Jogo por tacadas[1] (stroke play[2]), também c...   \n",
       "3      1  A bola é um objeto utilizado para lazer de uma...   \n",
       "4      2  Golfe é um esporte no qual os jogadores usam d...   \n",
       "5      3  Jogo por tacadas[1] (stroke play[2]), também c...   \n",
       "\n",
       "                  question expected_answer  expected_retriever_answer  \n",
       "0  Qual o formato da bola?        esférica                          1  \n",
       "1  Qual o formato da bola?        esférica                          1  \n",
       "2  Qual o formato da bola?        esférica                          1  \n",
       "3  Aonde se pratica golfe?  campo de golfe                          2  \n",
       "4  Aonde se pratica golfe?  campo de golfe                          2  \n",
       "5  Aonde se pratica golfe?  campo de golfe                          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteúdo da tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert parameters\n",
    "\n",
    "assert context_column_name in df.columns, f\"Coluna '{context_column_name}' deve ser uma coluna do dataset.\"\n",
    "assert question_column_name in df.columns, f\"Coluna '{question_column_name}' deve ser uma coluna do dataset.\"\n",
    "assert expected_column_name == \"\" or expected_column_name in df.columns, f\"Coluna '{expected_column_name}' deve ser uma coluna do dataset ou deixar ou campo em branco.\"\n",
    "assert identifier_column_name == \"\" or identifier_column_name in df.columns, f\"Coluna '{identifier_column_name}' deve ser uma coluna do dataset ou deixar ou campo em branco.\"\n",
    "if expected_column_name != \"\" and identifier_column_name == \"\":\n",
    "    assert False, f\"Para utilizar a Coluna de Avaliação é necessário preencher a Coluna de Identificação.\"\n",
    "assert proba_column_name not in df.columns and proba_column_name != \"\", f\"Coluna '{proba_column_name}' não pode ser vazia e nem uma coluna do dataset.\"\n",
    "assert device in ['cuda', 'cpu'], f\"Dispositivo '{device}' deve ser ou 'cuda' ou 'cpu'.\"\n",
    "assert topn > 0, \"Top N Contextos deve ser maior do que 0\"\n",
    "assert similarity_model in [\"paraphrase_multilingual\",\"bm25\",\"tf_idf\",\"word2vec\"], f\"Modelo '{similarity_model}' deve ser ou 'paraphrase_multilingual', ou 'bm25', ou 'tf_idf', ou 'word2vec'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Model parameters\n",
    "model_parameters = {\n",
    "    'device':torch.device(device) if torch.cuda.is_available() else torch.device('cpu'),\n",
    "}\n",
    "    \n",
    "# Inference parameters\n",
    "inference_parameters = {\n",
    "    'context_column_name':context_column_name,\n",
    "    'question_column_name':question_column_name,\n",
    "    'expected_column_name':expected_column_name,\n",
    "    'identifier_column_name':identifier_column_name,\n",
    "    'input_columns': list(df.columns),\n",
    "    'proba_column_name': proba_column_name,\n",
    "    'output_columns': list(df.columns) + [proba_column_name],\n",
    "    'topn': topn,\n",
    "    'similarity_model': similarity_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-21 15:34:10.900176: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_lg --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retriever import Retriever, MODEL_MAPPING\n",
    "\n",
    "# Initilizate Retriever\n",
    "sim_model = MODEL_MAPPING[inference_parameters['similarity_model']](**model_parameters)\n",
    "retriever = Retriever(similarity_model=sim_model, **model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique questions\n",
    "unique_questions = list(df[inference_parameters['question_column_name']].unique())\n",
    "\n",
    "# Initialize output df\n",
    "output_df = pd.DataFrame(columns=inference_parameters['output_columns'])\n",
    "\n",
    "# Iterate over each unique question\n",
    "for question in unique_questions:\n",
    "    \n",
    "    # Filter df per question\n",
    "    question_df = df[df[inference_parameters['question_column_name']] == question]\n",
    "    \n",
    "    # Get Contexts\n",
    "    contexts = list(question_df[inference_parameters['context_column_name']])\n",
    "    \n",
    "    # Get indices\n",
    "    context_ids = list(question_df.index)\n",
    "    \n",
    "    # Retrieve contexts\n",
    "    topn_ids, topn_scores = retriever.retrieve_top(contexts, question, topn=inference_parameters['topn'], context_ids=context_ids)\n",
    "    \n",
    "    # Retrieved df\n",
    "    retrieved_df = df.loc[topn_ids]\n",
    "    retrieved_df.at[topn_ids, inference_parameters['proba_column_name']] = topn_scores\n",
    "    \n",
    "    # Save to output\n",
    "    output_df = pd.concat((output_df, retrieved_df)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(dataset, index=False)\n",
    "del retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.plotting import plot_data_table\n",
    "from mrr import MRR\n",
    "# Evaluate translation (Optional)\n",
    "\n",
    "# Iff is not empty\n",
    "if inference_parameters['expected_column_name'] != \"\":\n",
    "    \n",
    "    # Initializate calculators\n",
    "    ranker1 = MRR(max_rank=1)\n",
    "    ranker10 = MRR(max_rank=10)\n",
    "    ranker100 = MRR(max_rank=100)\n",
    "    \n",
    "    # Get expected/predicted answers\n",
    "    expected_answers = []\n",
    "    predicted_answers = []\n",
    "    for question in unique_questions:\n",
    "        \n",
    "        # Filter output data\n",
    "        question_df = output_df[output_df[inference_parameters['question_column_name']] == question]\n",
    "        \n",
    "        # Retrieve expected answer\n",
    "        expected_answer = question_df[inference_parameters['expected_column_name']].values[0]\n",
    "        \n",
    "        # Retrieve predicted order\n",
    "        predicted_answer = question_df[inference_parameters['identifier_column_name']].values\n",
    "        \n",
    "        # Append answers\n",
    "        expected_answers.append(expected_answer)\n",
    "        predicted_answers.append(predicted_answer)\n",
    "    \n",
    "    # Perform calculations\n",
    "    scores = {}\n",
    "    scores['MRR@1'] = ranker1(predicted_answers, expected_answers)\n",
    "    scores['MRR@10'] = ranker10(predicted_answers, expected_answers)\n",
    "    scores['MRR@100'] = ranker100(predicted_answers, expected_answers)\n",
    "    \n",
    "    # Plot metrics\n",
    "    plot_data_table(pd.DataFrame(scores, index = ['Valor']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva resultados da tarefa\n",
    "\n",
    "A plataforma guarda o conteúdo de `/tmp/data/` para as tarefas subsequentes.<br>\n",
    "Use essa pasta para salvar modelos, metadados e outros resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/data/retriever.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "artifacts = {\n",
    "    \"model_parameters\": model_parameters,\n",
    "    \"inference_parameters\": inference_parameters\n",
    "}\n",
    "\n",
    "dump(artifacts, \"/tmp/data/retriever.joblib\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "fbb8236f-0904-4b10-a3e4-114e475a5947",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "operator_id": "c740820e-ef3b-40dc-81a7-75f12ecb448c",
  "task_id": "b565bc02-738f-4624-abf9-6a4c52028a60"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
