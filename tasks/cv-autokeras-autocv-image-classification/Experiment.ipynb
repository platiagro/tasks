{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoKeras AutoCV para Classificação de Imagens - Experimento\n",
    "\n",
    "Este componente utiliza [AutoKeras](https://autokeras.com/) AutoCV para a **tarefa de classificação**.\n",
    "\n",
    "O algoritmo faz a busca por arquiteturas e hyperparâmetros que melhor configuram o modelo\n",
    "para a base de dados fornecida.\n",
    "\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "A variável `dataset` possui o caminho para leitura do arquivos importados na tarefa de \"Upload de dados\".<br>\n",
    "Você também pode importar arquivos com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esse componente, a base de dados deve estar no seguinte formado:\n",
    "- Arquivo CSV chamado dataset.csv contendo as colunas \"image_path\", \"target\" e \"subset\", onde:\n",
    "    - image_path: caminho para o arquivo de imagem.\n",
    "    - target: resposta esperada da predição, caso exista.\n",
    "    - subset: conjunto ao qual a amostra faz parte, pode ser \"train\", \"test\", e \"val\". \n",
    "- Imagens coloridas (3 canais) no formato 256x256 pixels. Caso não estejam nesse formato, o código faz as alterações necesssárias\n",
    "- Cada classe tem sua pasta com suas respectivas imagens, além dos conjuntos de treino, validação e teste terem suas pastas separadas. Um exemplo da árvore de diretórios pode ser observado abaixo:\n",
    "\n",
    "\n",
    "```bash\n",
    "dataset\n",
    "|________dataset.csv\n",
    "|________train\n",
    "|        |_____class_name1\n",
    "|        |     |____image0.jpg\n",
    "|        |     |____image1.jpg\n",
    "|        |     ...\n",
    "|        |\n",
    "|        |_____class_name2\n",
    "|              |____image3.jpg\n",
    "|              |____image4.jpg\n",
    "|               ...\n",
    "|\n",
    "|________val\n",
    "|        |_____class_name1\n",
    "|        |     |____image5.jpg\n",
    "|        |     |____image6.jpg\n",
    "|        |     ...\n",
    "|        |\n",
    "|        |_____class_name2\n",
    "|              |____image7.jpg\n",
    "|              |____image8.jpg\n",
    "|               ...\n",
    "|\n",
    "|________test\n",
    "|        |_____class_name1\n",
    "|        |     |____image9.jpg\n",
    "|        |     |____image10.jpg\n",
    "|        |     ...\n",
    "|        |\n",
    "|        |_____class_name2\n",
    "|              |____image11.jpg\n",
    "|              |____image12.jpg\n",
    "|              ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"/tmp/data/beans_disease.zip\" #@param {type:\"string\"}\n",
    "num_epochs = 16 #@param {type:\"integer\", label: \"Número de épocas\", description: \"Número de épocas que serão utilizadas para realizar as buscas.\"}\n",
    "trials = 5 #@param {type:\"integer\", label: \"Número de tentativas\", description: \"Número de tentativas para o algoritmo de busca por arquiteturas e hyperparametros.\"}\n",
    "batch_size = 8 #@param {type:\"integer\", label: \"Tamanho de batch\", description: \"Quantidade de amostras em cada batch.\"}\n",
    "target_size = 256 #@param {type:\"integer\", label: \"Tamanho da entrada\", description: \"Representa o tamanho da imagem de entrada das redes, o mesmo valor sera utilizado como altura e largura da imagem.\"}\n",
    "\n",
    "'''\n",
    "[OPCIONAIS]\n",
    "Aumentações são técnicas que comprovadamente ajudam \n",
    "a melhorar o desempenho e generalização dos modelos.\n",
    "Essas técnicas serão utilizadas apenas nos conjuntos de treino e validação. \n",
    "Não utilizadas no conjunto de teste.\n",
    "Possibilidades de aumentações para utilizar no dataset estão listadas abaixo:\n",
    "\n",
    "Mais explicações sobre cada aumentação podem ser encontradas no link:\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "'''\n",
    "\n",
    "brightness_range = None #@param {type:\"float\", label: \"Brightness Range\", description: \"[Opcional; Aumentação] Tupla ou lista de dois float. Faixa para escolher o valor da mudança de brilho. Padrão: None\"}\n",
    "channel_shift_range = 0.0 #@param {type:\"float\", label: \"Channel Shift Range\", description: \"[Opcional; Aumentação] Faixa para mudanças aleatórias dos canais. Padrão: 0.0\"}\n",
    "cval = 0.0 #@param {type:\"float\", label: \"cval\", description: \"[Opcional; Aumentação] Float or Int. Valor usado para pontos fora dos limites quando fill_mode = \"constant\". Padrão: 0.0\"}\n",
    "data_format = \"channels_last\" #@param [\"channels_first\", \"channels_last\"]{type:\"string\", label: \"Data Format\", description: \"[Opcional; Aumentação] Formato dos dados da imagem. Padrão:\"channels_last\".\"}\n",
    "dtype = 'float32' #@param {type:\"string\", label: \"dtype\", description: \"[Opcional; Aumentação] Dtype para usar nos arrays gerados.\"}\n",
    "featurewise_center = False #@param {type:\"bool\", label: \"Featurewise Center\", description: \"[Opcional; Aumentação] Faz a média igual a zero em todo o dataset em termos de features.\"}\n",
    "featurewise_std_normalization = False #@param {type:\"bool\", label: \"Featurewise std Normalization\", description: \"[Opcional; Aumentação] Divide entradas pelo desvio padrão (std) do dataset em termos de features.\"}\n",
    "fill_mode = 'nearest' #@param [\"constant\", \"nearest\", \"reflect\", \"wrap\"]{type:\"string\", label: \"Fill Mode\", description:\"[Opcional; Aumentação] Algoritmo usado para preencher regiões caso necessário. Padrão:nearest\".}\n",
    "horizontal_flip = False #@param {type:\"bool\", label: \"Horizontal Flip\", description:\"[Opcional; Aumentação] Aplica inversão horizontal nas entragas aleatoriamente.\"}\n",
    "preprocessing_function = None #@param {type:\"string\", label: \"Preprocessing Function\", description:\"[Opcional; Aumentação] Funções que serão aplicadas em cada entrada. A função irá rodar após a imagem ser aumentada e redimensionada.\"}\n",
    "rescale = 1./255 #@param {type:\"float\", label: \"Rescale\", description:\"[Opcional; Aumentação] Fator de re-escala. Se None ou 0, nenhuma re-escala será aplicada, caso contrário cada data será multiplicado pelo valor especificado. Padrão: 1./255\"}\n",
    "rotation_range = 0 #@param {type:\"integer\", label: \"Rotation Range\", description:\"[Opcional; Aumentação] Faixa de graus para rotações aletórias. Padrão: 0\"}\n",
    "samplewise_center = False #@param {type:\"bool\", label: \"Samplewise Center\", description:\"[Opcional; Aumentação] Define cada média de amostra para 0. Padrão: False\"}\n",
    "samplewise_std_normalization = False #@param {type:\"bool\", label: \"Samplewise std Normalization\", description:\"[Opcional; Aumentação] Divide cada entrada por seu desvio padrão. Padrão: False\"}\n",
    "shear_range = 0.0 #@param {type:\"float\", label: \"Shear Range\", description:\"[Opcional; Aumentação] Intensidade de corte (Ângulo de corte na direção anti-horária em graus). Padrão: 0.0\"}\n",
    "vertical_flip = False #@param {type:\"bool\", label: \"Vertical Flip\", description:\"[Opcional; Aumentação] Aplica inversão vertical nas entragas aleatoriamente. Padrão: False\"}\n",
    "zca_whitening = False #@param {type:\"bool\", label: \"Zca Whitening\", description:\"[Opcional; Aumentação] Aplica clareamento ZCA. Padrão: False\"}\n",
    "zca_epsilon = 1e-06 #@param {type:\"float\", label: \"Zca Epsilon\", description:\"[Opcional; Aumentação] Valor de epsilon para clareamento ZCA. Padrão: 1e-6.\"}\n",
    "zoom_range = 0.0 #@param {type:\"float\", label: \"Zoom Range\", description:\"[Opcional; Aumentação] Float ou [lower, upper]. Faixa para zoom aleatório. Padrão: 0.0\"}\n",
    "height_shift_range = 0.0 #@param {type:\"float\", label: \"Height Shift Range\", description:\"[Opcional; Aumentação] Float, 1-D array-like ou integer. Padrão: 0.0\"} \n",
    "width_shift_range = 0.0 #@param {type:\"float\", label: \"Width Shift Range\", description:\"[Opcional; Aumentação] Float, 1-D array-like ou integer. Padrão: 0.0\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autokeras==1.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "root_folder_name = dataset.split(\"/\")[-1].split(\".\")[0]\n",
    "root_folder = os.path.join(\"/tmp/data\", root_folder_name)\n",
    "with zipfile.ZipFile(dataset, 'r') as zip_ref:\n",
    "    zip_ref.extractall(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação do iterador de dados para a fase de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(root_folder, 'train'),\n",
    "    labels='inferred', label_mode='int',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(root_folder, 'val'),\n",
    "    labels='inferred', label_mode='int',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "print(train_data.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciação do [autokeras](https://autokeras.com/tutorial/image_classification/) para Classificação de Imagens e busca pela melhor arquitetura e hyperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "model = ak.ImageClassifier(\n",
    "    num_classes=len(train_data.class_names),\n",
    "    max_trials=trials,\n",
    "    metrics=\"accuracy\",\n",
    "    objective=\"val_loss\",\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A busca por arquiteturas é feita utilizando apenas metade \n",
    "do número total de épocas. Após selecionada a melhor arquitetura \n",
    "e hyperparametros, um novo treinamento dessa arquitetura é realizado\n",
    "utilizando o número total de épocas e as técnicas de aumentação de\n",
    "dados escolhidas para obter o modelo com melhor performance.\n",
    "'''\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=int(num_epochs/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportação do melhor modelo e exposição da sua configuração de camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exported = model.export_model()\n",
    "model_exported.summary()\n",
    "model_path = \"/tmp/data/model_weights.h5\"\n",
    "model_exported.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação dos dataloaders para última fase de treino utilizando aumentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "    brightness_range = brightness_range,\n",
    "    channel_shift_range = channel_shift_range,\n",
    "    cval = cval,\n",
    "    data_format = data_format,\n",
    "    dtype = dtype,\n",
    "    featurewise_center = featurewise_center,\n",
    "    featurewise_std_normalization = featurewise_std_normalization,\n",
    "    fill_mode = fill_mode,\n",
    "    horizontal_flip = horizontal_flip,\n",
    "    preprocessing_function = preprocessing_function,\n",
    "    rescale = rescale,\n",
    "    rotation_range = rotation_range,\n",
    "    samplewise_center = False,\n",
    "    samplewise_std_normalization = samplewise_std_normalization,\n",
    "    shear_range = shear_range,\n",
    "    vertical_flip = vertical_flip,\n",
    "    zca_whitening = zca_whitening,\n",
    "    zca_epsilon = zca_epsilon,\n",
    "    zoom_range = zoom_range,\n",
    "    height_shift_range = height_shift_range,\n",
    "    width_shift_range = width_shift_range\n",
    ")\n",
    "\n",
    "train_generator = image_generator.flow_from_directory(\n",
    "    os.path.join(root_folder, 'train'),\n",
    "    batch_size=batch_size,\n",
    "    target_size=(target_size, target_size))\n",
    "\n",
    "val_generator = image_generator.flow_from_directory(\n",
    "    os.path.join(root_folder, 'val'),\n",
    "    batch_size=batch_size,\n",
    "    target_size=(target_size, target_size))\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=rescale,\n",
    "    dtype=dtype)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(root_folder, 'test'),\n",
    "    batch_size=batch_size,\n",
    "    target_size=(target_size, target_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treino do melhor modelo encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=num_epochs,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Acurácia do modelo\")\n",
    "plt.ylabel(\"acurácia\")\n",
    "plt.xlabel(\"época\")\n",
    "plt.legend([\"treino\", \"validação\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação do melhor modelo no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the best model\n",
    "loss, acc = model.evaluate(x=test_generator, verbose=True)\n",
    "print(\"Loss: {0} / Acc: {1}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(x=test_generator)\n",
    "preds = []\n",
    "for prediction in predictions:\n",
    "    indx = np.argmax(prediction)\n",
    "    preds.append([indx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geração do relatório de classificação e da matrix de confusão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "report = classification_report(\n",
    "    test_generator.classes, preds,\n",
    "    target_names=test_generator.class_indices.keys(),\n",
    "    output_dict=True)\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = confusion_matrix(test_generator.classes, preds)\n",
    "ticklabels = test_generator.class_indices.keys()\n",
    "ax = plt.axes()\n",
    "sns.heatmap((confusion_mtx/sum(confusion_mtx)), annot=True,\n",
    "            xticklabels=ticklabels, \n",
    "            yticklabels=ticklabels,\n",
    "            fmt='.02%',\n",
    "            cmap=sns.light_palette(\"seagreen\", as_cmap=True),\n",
    "            linewidths=0.2, ax = ax)\n",
    "\n",
    "ax.set_title('Matriz de Confusão')\n",
    "plt.xlabel('Classe Predita', fontsize = 15)\n",
    "plt.ylabel('Classe Real', fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Salva modelo e outros resultados do treinamento\n",
    "\n",
    "Escreve todos artefatos na pasta `/tmp/data/`. A plataforma guarda os artefatos desta pasta para usos futuros como implantação e comparação de resultados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(classification_report = report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva resultados da tarefa\n",
    "\n",
    "A plataforma guarda o conteúdo de `/tmp/data/` para as tarefas subsequentes.<br>\n",
    "Use essa pasta para salvar modelos, metadados e outros resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "artifacts = {\n",
    "    \"model_path\": model_path,\n",
    "    \"class_names\": test_generator.classes,\n",
    "}\n",
    "dump(artifacts, \"/tmp/data/model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "abd0eb69-15e2-429c-8196-3dac7c7fc42b",
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "operator_id": "c84fe669-c8d8-4a57-98a3-f15aa68ad22d",
  "task_id": "b7a312ca-5d66-4d18-a313-fd247933ed50",
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}