{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast AutoCV - Experimento\n",
    "\n",
    "Este componente utiliza o três arquiteturas presentes na biblioteca [PyTorch](https://pytorch.org/) para a tarefa de classificação de imagens. São elas: ResNet-18, ResNet-50 e VGG16.    \n",
    "Cada uma das arquiteturas é treinada aplicando-se no conjunto de treino e validação um dos 3 conjuntos de polices genéricas definidas pelo artigo [Fast AutoAugment](https://arxiv.org/pdf/1905.00397.pdf), sujo código está disponibilizado no [GitHub](https://github.com/kakaobrain/fast-autoaugment).\n",
    "\n",
    "Ao final, o modelo de maior acurácia no conjunto de validação para o dataset utilizado será salvo para futura utilização.\n",
    "#### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "O parâmetro `dataset` identifica os conjuntos de dados. Você pode importar arquivos de dataset com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esse componente, a base de dados deve estar no seguinte formado:\n",
    "- Imagens coloridas (3 canais) no formato 224x224 pixels. Caso não estejam nesse formato, o código faz as alterações necesssárias\n",
    "- Cada classe tem sua pasta com suas respectivas imagens, além dos conjuntos de treino, validação e teste terem suas pastas separadas. Um exemplo da árvore de diretórios pode ser observado abaixo:\n",
    "\n",
    "```bash\n",
    "dataset\n",
    "|\n",
    "|________train\n",
    "|        |_____class_name1\n",
    "|        |     |____image0.jpg\n",
    "|        |     |____image1.jpg\n",
    "|        |     ...\n",
    "|        |\n",
    "|        |_____class_name2\n",
    "|              |____image3.jpg\n",
    "|              |____image4.jpg\n",
    "|               ...\n",
    "|\n",
    "|________val\n",
    "|        |_____class_name1\n",
    "|        |     |____image5.jpg\n",
    "|        |     |____image6.jpg\n",
    "|        |     ...\n",
    "|        |\n",
    "|        |_____class_name2\n",
    "|              |____image7.jpg\n",
    "|              |____image8.jpg\n",
    "|               ...\n",
    "|\n",
    "|________test\n",
    "|        |_____class_name1\n",
    "|        |     |____image9.jpg\n",
    "|        |     |____image10.jpg\n",
    "|        |     ...\n",
    "|        |\n",
    "|        |_____class_name2\n",
    "|              |____image11.jpg\n",
    "|              |____image12.jpg\n",
    "|              ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"/tmp/data/hymenoptera_data-6.zip\" #@param {type:\"string\"}\n",
    "\n",
    "# Lista de arquiteturas disponívels: [resnet18, resnet50, vgg16]\n",
    "arch_list = [\"resnet18\", \"resnet50\", \"vgg16\"]\n",
    "# Lista de polices disponíveis:\n",
    "aug_polices = [\"fa_reduced_cifar10\", \"fa_resnet50_rimagenet\", \"fa_reduced_svhn\"]\n",
    "# Nome base para salvar os modelos\n",
    "dataset_id = \"hymenoptera\"\n",
    "# Caminho para salvar os checkpoints dos modelos treinados\n",
    "checkpoint_path = \"/tmp/data/models-output/\"\n",
    "# Caminha para salvar as imagens dos gráficos de loss e acurácia relativos aos treinamentos\n",
    "output_graphs = \"/tmp/data/eval-images/\"\n",
    "# Número de classes presentes no conjunto de dados\n",
    "num_of_classes = 2\n",
    "# Quantas predições queremos.\n",
    "# Deve ser menor ou igual ao número de classes\n",
    "top_predictions = 1\n",
    "\n",
    "# variáveis utilizadas na etapa de treinamento do modelo\n",
    "batch = 64\n",
    "epochs = 4\n",
    "lr = 0.001\n",
    "gamma = 0.1\n",
    "step_size = 7\n",
    "momentum = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Variáveis globais. Não modificar as 3 linhas abaixo.\n",
    "ARCH_LIST = ['resnet18', 'resnet50', 'vgg16']\n",
    "POLICES_LIST = ['fa_reduced_cifar10', 'fa_resnet50_rimagenet', 'fa_reduced_svhn']\n",
    "CSV_FILENAME = \"/tmp/data/best_models_acc.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de dados do arquivo .zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "root_folder_name = dataset.split(\"/\")[-1].split(\".\")[0]\n",
    "root_folder = os.path.join(\"/tmp/data\", root_folder_name)\n",
    "with zipfile.ZipFile(dataset, 'r') as zip_ref:\n",
    "   zip_ref.extractall(root_folder)\n",
    "\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar functions to print trained models infos \n",
    "# and select best model\n",
    "\n",
    "def save_to_csv(csv_path, arch, police, val_acc):\n",
    "    \"\"\"Save a csv file with best models infos\"\"\"\n",
    "    data = {\n",
    "        \"dataset\": [dataset_id],\n",
    "        \"architecture_id\": [arch],\n",
    "        \"police_id\": [police],\n",
    "        \"val_acc\": [val_acc]}\n",
    "    dataframe = pd.DataFrame(data)\n",
    "    output_path = os.path.join(csv_path, CSV_FILENAME)\n",
    "    if os.path.isfile(output_path):\n",
    "        dataframe.to_csv(output_path, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        dataframe.to_csv(output_path, index=False)\n",
    "\n",
    "def best_models_stats(csv):\n",
    "    \"\"\"Print best model and all trained models\"\"\"\n",
    "    dataframe = pd.read_csv(csv)\n",
    "    dataframe.sort_values(by=[\"val_acc\"], inplace=True, ascending=False)\n",
    "    dataframe.reset_index(drop=True, inplace=True)\n",
    "    best_cases = dataframe.loc[dataframe['dataset'] == dataset_id].head()\n",
    "    print(\"### TOP 5 BEST MODELS ON {0} DATASET ###\\n\".format(dataset_id))\n",
    "    print(best_cases, \"\\n\")\n",
    "    print(\"### ALL MODELS TRAINED ON {0} DATASET ### \\n\".format(dataset_id))\n",
    "    print(dataframe.loc[dataframe['dataset'] == dataset_id], \"\\n\")\n",
    "    \n",
    "    best_model = best_cases.iloc[0]\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/platiagro/tasks/feature/autocv/tasks/cv-fast-autocv/archive.py\n",
    "!wget https://raw.githubusercontent.com/platiagro/tasks/feature/autocv/tasks/cv-fast-autocv/augmentations.py\n",
    "!wget https://raw.githubusercontent.com/platiagro/tasks/feature/autocv/tasks/cv-fast-autocv/checkpoint.py\n",
    "!wget https://raw.githubusercontent.com/platiagro/tasks/feature/autocv/tasks/cv-fast-autocv/data.py\n",
    "!wget https://raw.githubusercontent.com/platiagro/tasks/feature/autocv/tasks/cv-fast-autocv/finetuning.py\n",
    "!wget https://raw.githubusercontent.com/platiagro/tasks/feature/autocv/tasks/cv-fast-autocv/models.py\n",
    "!wget https://raw.githubusercontent.com/platiagro/tasks/feature/autocv/tasks/cv-fast-autocv/networks.py\n",
    "!wget https://raw.githubusercontent.com/platiagro/tasks/feature/autocv/tasks/cv-fast-autocv/visualizations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import cuda\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from data import LoadData\n",
    "from finetuning import FineTuning\n",
    "from visualizations import ImageVisualization\n",
    "from checkpoint import Checkpoint\n",
    "from models import Model, ModelInfos\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, type(device))\n",
    "\n",
    "multi_gpu = False\n",
    "if cuda.is_available():\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(gpu_count, ' gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "l_data = LoadData(root_folder)\n",
    "checkpoint = Checkpoint(dataset_id, multi_gpu, checkpoint_path)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_ft = FineTuning(arch_list, num_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for police in aug_polices:\n",
    "    assert (police in POLICES_LIST), 'police not found'\n",
    "    dataloaders, dataset_sizes, class_names = l_data.load_data_train(police)\n",
    "    visual = ImageVisualization(device, dataloaders, output_graphs)\n",
    "    for arch in arch_list:\n",
    "        assert (arch in ARCH_LIST), 'archictecture not supported'\n",
    "        model_train = Model(arch, device, checkpoint)\n",
    "        model_name = \"{0}_{1}_{2}\".format(dataset_id, arch, police)\n",
    "        model_path = os.path.join(checkpoint_path, model_name)\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            model_conv = model_ft.fine_tuning(arch)\n",
    "            optimizer_conv = optim.SGD(\n",
    "                model_conv.parameters(),\n",
    "                lr=lr, momentum=momentum)\n",
    "            exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "                optimizer_conv, step_size=step_size, gamma=gamma)\n",
    "            model_conv, best_model_val_acc = model_train.train_model(\n",
    "                model_conv, police, dataloaders, dataset_sizes, criterion,\n",
    "                optimizer_conv, exp_lr_scheduler, num_epochs=epochs)\n",
    "            save_to_csv(checkpoint_path, arch, police, best_model_val_acc)\n",
    "            visual.visualize_results(model_conv.history, dataset_id + '_' + arch + '_' + police)\n",
    "\n",
    "        elif os.path.exists(model_path):\n",
    "            model_checkpoint = checkpoint.load_checkpoint(\n",
    "                arch,\n",
    "                checkpoint_path + dataset_id + '_' + arch + '_' + police)\n",
    "            exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "                model_checkpoint.optimizer, step_size=step_size,\n",
    "                gamma=gamma)\n",
    "            model_checkpoint, best_model_val_acc = model_train.train_model(\n",
    "                model_checkpoint, police, dataloaders,dataset_sizes, criterion,\n",
    "                model_checkpoint.optimizer, exp_lr_scheduler, num_epochs=epochs)\n",
    "            save_to_csv(checkpoint_path, arch, police, best_model_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_models_stats(os.path.join(checkpoint_path, CSV_FILENAME))\n",
    "best_model_name = \"{0}_{1}_{2}\".format(best_model['dataset'], best_model['architecture_id'], best_model['police_id'])\n",
    "best_model_path = os.path.join(checkpoint_path, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Teste do melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = best_model_path\n",
    "dataloaders, dataset_sizes, class_names = l_data.load_data_test()\n",
    "\n",
    "# Run inference for test set\n",
    "model = Model(best_model['architecture_id'], device)\n",
    "acc_per_class, confusion_matrix, report = model.predict_batch(\n",
    "    multi_gpu,\n",
    "    model_path,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    class_names)\n",
    "\n",
    "print(\"Acurácia por classe:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(\"Class: {0} -> Acc: {1}\".format(class_names[i], acc_per_class[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva métricas\n",
    "Utiliza a função `save_metrics` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar métricas. Por exemplo: `accuracy`, `precision`, `r2_score`, `custom_score` etc.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "import pandas as pd\n",
    "\n",
    "confusion_matrix = pd.DataFrame(confusion_matrix, columns=class_names, index=class_names)\n",
    "save_metrics(confusion_matrix=confusion_matrix)\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "save_metrics(classification_report=report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva modelo e outros resultados do treinamento\n",
    "\n",
    "Escreve todos artefatos na pasta `/tmp/data/`. A plataforma guarda os artefatos desta pasta para usos futuros como implantação e comparação de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "artifacts = {\n",
    "    \"model_arch\": best_model['architecture_id'],\n",
    "    \"dataset\": best_model['dataset'], \n",
    "    \"model_police\": best_model['police_id'],\n",
    "    \"model_name\": best_model_name,\n",
    "    \"model_path\": best_model_path,\n",
    "    \"class_names\": class_names\n",
    "}\n",
    "dump(artifacts, '/tmp/data/model.joblib')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "ec73ad1f-1fed-463f-9c92-142955e254af",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "operator_id": "d823b585-3a98-4a3c-a838-8d817993d2b4",
  "task_id": "a17aab85-fb3b-447b-a39a-cd55743a3561"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}