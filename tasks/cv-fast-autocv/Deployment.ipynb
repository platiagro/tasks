{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast AutoCV - Implantação\n",
    "\n",
    "- Esse componente utiliza modelos para classificação de imagens disponíveis na biblioteca [PyTorch](https://pytorch.org/) previamente treinados utilizando polices genéricas encontradas pelo artigo [Fast AutoAugment](https://github.com/kakaobrain/fast-autoaugment/tree/master/FastAutoAugment)\n",
    "\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de Classe para Predições em Tempo Real\n",
    "\n",
    "A tarefa de implantação cria um serviço REST para predições em tempo-real.<br>\n",
    "Para isso você deve criar uma classe `Model` que implementa o método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Model.py\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "from checkpoint import Checkpoint\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.loaded = False\n",
    "    \n",
    "    def load(self):\n",
    "        # Following links explain why to use load() method insted of __init__()\n",
    "\n",
    "        # Issue associated with sheldon on __init__\n",
    "        # https://github.com/SeldonIO/seldon-core/issues/2616\n",
    "\n",
    "        # Solution for the case\n",
    "        # https://docs.seldon.io/projects/seldon-core/en/latest/python/python_component.html#gunicorn-and-load\n",
    "\n",
    "        \n",
    "        artifacts = joblib.load(\"/tmp/data/model.joblib\")\n",
    "        self.model_name = artifacts[\"model_name\"]\n",
    "        self.model_path = artifacts[\"model_path\"]\n",
    "        self.model_arch = artifacts[\"model_arch\"]\n",
    "        self.dataset = artifacts[\"dataset\"]\n",
    "        self.used_police = artifacts[\"model_police\"]\n",
    "        self.class_names = artifacts[\"class_names\"] \n",
    "        self.loaded = True\n",
    "\n",
    "    def process_image(self, image):\n",
    "        \"\"\"Prepare single image for inference\"\"\"\n",
    "        \n",
    "        img = cv2.resize(image, (224, 224))\n",
    "        # Convert to numpy, transpose color dimension and normalize\n",
    "        img = np.array(img).transpose((2, 0, 1)) / 255\n",
    "        # Standardization\n",
    "        means = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "        stds = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "        img = img - means\n",
    "        img = img / stds\n",
    "        img_tensor = torch.Tensor(img)\n",
    "\n",
    "        return img_tensor\n",
    "    \n",
    "    def predict(self, X: np.ndarray, feature_names, meta=None):\n",
    "        # First time load model\n",
    "        if not self.loaded:\n",
    "            self.load()\n",
    "        # Rodar inferencia em cpu\n",
    "        device = torch.device(\"cpu\")\n",
    "        multi_gpu = False\n",
    "        \n",
    "        # Decode image\n",
    "        im_bytes = base64.b64decode(X[0,0])\n",
    "        im_arr = np.frombuffer(im_bytes, dtype=np.uint8)\n",
    "        image = cv2.imdecode(im_arr, flags=cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # Selecionar apenas a classe predita de maior probabilidade\n",
    "        topk = 1\n",
    "        checkpoint = Checkpoint(self.model_arch, multi_gpu)\n",
    "        model = checkpoint.load_checkpoint(self.model_arch, self.model_path)\n",
    "\n",
    "        # Converte imagem em tensor do pytorch\n",
    "        img_tensor = self.process_image(image)\n",
    "        img_tensor = img_tensor.view(1, 3, 224, 224).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            out = model(img_tensor)\n",
    "            ps = torch.exp(out)\n",
    "\n",
    "            topk, topclass = ps.topk(topk, dim=1)\n",
    "            topk_index = topclass.cpu().numpy()[0]\n",
    "            topk_prob = topk.cpu().numpy()[0]\n",
    "            result = {\"class_index\": int(topk_index), \"class_name\": self.class_names[int(topk_index)], \"class_probability\": float(topk_prob)}\n",
    "        return result\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "d2e42cfe-abc9-4ab3-aecd-566b98ff5059",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "operator_id": "df95f75a-d675-4aea-8e35-9ff7a964977e",
  "task_id": "ee9520cf-aeb8-487c-b6d4-6f9283e99ebd"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}