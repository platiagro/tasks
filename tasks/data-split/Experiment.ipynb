{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split - Experimento\n",
    "\n",
    "Este componente separa os dados em \"treino\", \"validação\" e \"teste\" podendo ter seus parâmetro customizados para separações mais eficientes. <br>\n",
    "Essas separações podem ser feitas para deixar os conjuntos balanceados, portanto alterar o parâmetro \"strat\", ou garantir que mesmas observações(ID's iguais) não estejam em conjuntos diferentes, portantro alterar o parâmetro \"split_ids\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "A variável `dataset` possui o caminho para leitura do arquivos importados na tarefa de \"Upload de dados\".<br>\n",
    "Você também pode importar arquivos com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "dataset = \"/tmp/data/Iris.csv\" #@param {type:\"string\"}\n",
    "split_train = 80 #@param {type:\"integer\", label:\"Porcentagem dedicada ao treino\", description: \"Tamanho em porcentagem do conjunto de treino, o restante será o conjunto de validação. Nesta porção não estará contida a porção dedicada ao teste.\"}\n",
    "split_test = 30 #@param {type:\"integer\", label:\"Porcentagem dedicada ao teste\", description: \"Tamanho em porcentagem do conjunto de teste, será subtraido do conjunto de validação.\"}\n",
    "\n",
    "strat = None #@param {type:\"feature\",multiple:false,label:\"Garante a mesma proporção de cada categoria da feature selecionada para os conjuntos de treino, validação e teste.\", description: \"Será usado a codificação ordinal se o atributo for categórico.\"}\n",
    "split_ids = None #@param {type:\"feature\",multiple:false,label:\"Atributo que restringe o mesmo ID de apareçer em mais de 1 conjunto, seja treino, validação ou teste.\", description: \"Não permitirá que IDs iguais fiquem em conjuntos diferentes.\"}\n",
    "kfolds = None #@param {type:\"integer\", label:\"Deseja usar validação cruzada será usada para validar algumas métricas do modelo? Se sim especifique a quantidade de dobras(folds).\", description: \" Recomenda-se o uso com poucas amostras.\"}\n",
    "loo = None #@param {type:\"integer\", label:\"Deseja usar a validação do estilo \"leave-one-out\"? Será usada para validar algumas métricas do modelo.\", description: \"Caso especial do validação crizada, recomenda-se o uso com pouquíssimas amostras.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso ao conjunto de dados\n",
    "\n",
    "O conjunto de dados utilizado nesta etapa será o mesmo carregado através da plataforma.<br>\n",
    "O tipo da variável retornada depende do arquivo de origem:\n",
    "- [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) para CSV e compressed CSV: .csv .csv.zip .csv.gz .csv.bz2 .csv.xz\n",
    "- [Binary IO stream](https://docs.python.org/3/library/io.html#binary-i-o) para outros tipos de arquivo: .jpg .wav .zip .h5 .parquet etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(dataset)\n",
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando em conjunto de Treino, Validação e Teste\n",
    "\n",
    "Utiliza a função `stat_dataset` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para carregar metadados. <br>\n",
    "Por exemplo, arquivos CSV possuem `metadata['featuretypes']` para cada coluna no conjunto de dados (ex: categorical, numerical, or datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "if strat != None:\n",
    "    balancy = df[strat]\n",
    "else:\n",
    "    balancy = None\n",
    "\n",
    "if split_ids == None:\n",
    "    \n",
    "    # separo em treino/test\n",
    "    X_train, X_test, idx1, idx2 = train_test_split(df, df.index, train_size=split_train/100, stratify = balancy)\n",
    "    data = {'idx': np.concatenate([idx1,idx2]),\n",
    "        'data-split': np.concatenate([ [0]*len(idx1),[1]*len(idx2)])\n",
    "        }\n",
    "    split = pd.DataFrame(data, columns = ['idx', 'data-split'])\n",
    "    df[\"data-split\"] = split.sort_values(by=['idx']).set_index('idx')[\"data-split\"]\n",
    "    \n",
    "    #caso não tenha cv-> treino/val/teste\n",
    "    if kfolds == None and loo == None:\n",
    "\n",
    "        df_to_val_test = df.loc[df['data-split'] == 1].copy()\n",
    "        df_train = df.loc[df['data-split'] == 0]\n",
    "        \n",
    "        if strat != None:\n",
    "            balancy = X[strat]\n",
    "    \n",
    "        X_test, X_val, idx1, idx2 = train_test_split(df_to_val_test, df_to_val_test.index, test_size=split_test/100, stratify = balancy)\n",
    "        data = {'idx': np.concatenate([idx1,idx2]),\n",
    "                'data-split': np.concatenate([ [2]*len(idx1),[1]*len(idx2)])\n",
    "                }\n",
    "        split_aux = pd.DataFrame(data, columns = ['idx', 'data-split'])\n",
    "        df_to_val_test[\"data-split\"] = split_aux.sort_values(by=['idx']).set_index('idx')[\"data-split\"]\n",
    "        df = pd.concat([df_to_val_test, df_train])\n",
    "\n",
    "else:\n",
    "    \n",
    "    #caso onde separo restringindo os ids -> treino/teste\n",
    "    train_inds, test_inds = next(GroupShuffleSplit(train_size=split_train/100, n_splits=2, random_state = 42).split(df, groups=df[split_ids]))\n",
    "    data = {'idx': np.concatenate([train_inds,test_inds]),\n",
    "            'data-split': np.concatenate([ [0]*len(train_inds),[1]*len(test_inds)])\n",
    "            }\n",
    "    split = pd.DataFrame(data, columns = ['idx', 'data-split'])\n",
    "    df[\"data-split\"] = np.array(split.sort_values(by=['idx']).set_index('idx')[\"data-split\"])\n",
    "\n",
    "    if split_test != 0:\n",
    "\n",
    "        #caso onde separo restringindo os ids -> treino/validação/teste  \n",
    "        df_to_val_test = df.loc[df['data-split'] == 1].copy()\n",
    "        df_train = df.loc[df['data-split'] == 0]\n",
    "        test_inds, val_inds = next(GroupShuffleSplit(test_size=split_test/100, n_splits=2, random_state = 7).split(df_to_val_test, groups=df_to_val_test[split_ids]))\n",
    "        data = {'idx': np.concatenate([test_inds,val_inds]),\n",
    "                'data-split': np.concatenate([ [2]*len(test_inds),[1]*len(val_inds)])\n",
    "                }\n",
    "        split_aux = pd.DataFrame(data, columns = ['idx', 'data-split'])\n",
    "        df_to_val_test[\"data-split\"] = np.array(split_aux.sort_values(by=['idx']).set_index('idx')[\"data-split\"])\n",
    "        df = pd.concat([df_to_val_test, df_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dataset, index=False)\n",
    "features_after_pipeline = df.columns\n",
    "new_column_name = \"data-split\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva resultados da tarefa \n",
    "\n",
    "A plataforma guarda o conteúdo de `/tmp/data/` para as tarefas subsequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "artifacts = {\n",
    "    \"columns\": columns,\n",
    "    \"new_column_name\" = new_column_name,\n",
    "    \"new_columns\": df[\"data-split\"],\n",
    "    \"features_after_pipeline\": features_after_pipeline,\n",
    "    \"n_folds\": kfolds,\n",
    "    \"use_loo\": loo\n",
    "}\n",
    "\n",
    "dump(artifacts, \"data-split.joblib\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "e2f7a23aa597faf5fffb565a46a7c43a2cecc809ad571b7c090617ffc934dbfc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "task_id": "d85a990e-4886-48a2-9350-0e7eb9a4f60e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
