{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#  Chunker de Textos - Implantação\n",
    "\n",
    "* Este componente requer conexão com a internet para o download online de dependências do NLTK.\n",
    "* Este componente faz janelamento de textos longos, dividindo um texto em partes menores, cada parte de texto criada (chunk), possui uma quantidade de elementos (palavras ou sentenças) pré-definidas pelo usuário; como também a quantidade de elementos que se sobrepõem entre cada chunk consecutivo. \n",
    "* Exemplo:\n",
    "        \n",
    "    - Texto: \"Hoje o dia amanheceu ensolarado, vou fazer uma caminhada e ouvir os sons da natureza.\"\n",
    "\n",
    "    - Hiperparâmetros: {\n",
    "        \"chunkenizer\": \"word\",\n",
    "        \"chunk_size\": 5,\n",
    "        \"chunk_overlap\": 2\n",
    "    }\n",
    "\n",
    "    - Saída: [\n",
    "        \"Hoje o dia amanheceu ensolarado,\",\n",
    "        \"amanheceu ensolarado, vou fazer uma\",\n",
    "        \"fazer uma caminhada e ouvir\",\n",
    "        \"e ouvir os sons da\",\n",
    "        \"sons da natureza.\"\n",
    "    ]\n",
    "\n",
    "\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Declaração de Classe para Predições em Tempo Real\n",
    "\n",
    "A tarefa de implantação cria um serviço REST para predições em tempo-real.<br>\n",
    "Para isso você deve criar uma classe `Model` que implementa o método `predict`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%%writefile Model.py\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chunker import Chunker\n",
    "from utils import generate_dataframe\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.loaded = False\n",
    "\n",
    "    def load(self):\n",
    "        \n",
    "        # Load artifacts\n",
    "        artifacts = joblib.load(\"/tmp/data/chunker.joblib\")\n",
    "        self.model_parameters = artifacts[\"model_parameters\"]\n",
    "        self.inference_parameters = artifacts[\"inference_parameters\"]\n",
    "        \n",
    "        # Initialize chunker\n",
    "        self.chunker = Chunker(**self.model_parameters)\n",
    "        \n",
    "        # Set model loaded\n",
    "        self.loaded = True\n",
    "        print(\"Loaded model\")\n",
    "    \n",
    "    def class_names(self):\n",
    "        column_names = list(self.inference_parameters['columns']) + [self.inference_parameters['output_column_name']]\n",
    "        return column_names\n",
    "\n",
    "    def predict(self, X, feature_names, meta=None):\n",
    "        if not self.loaded:\n",
    "            self.load()\n",
    "            \n",
    "        if feature_names:\n",
    "            # Antes de utilizar o conjunto de dados X no modelo, reordena suas features de acordo com a ordem utilizada no treinamento\n",
    "            df = pd.DataFrame(X, columns=feature_names)\n",
    "            X = df[self.inference_parameters['columns']]\n",
    "        \n",
    "        else:\n",
    "            X = pd.DataFrame(X, columns=self.inference_parameters['columns'])\n",
    "            \n",
    "        # Generate Chunks\n",
    "        chunks = self.chunker(X[self.inference_parameters['text_column_name']])\n",
    "        \n",
    "        # Generate Dataframe\n",
    "        if self.inference_parameters['replicate_data'] == 'sim':\n",
    "            # Replicate Data\n",
    "            output_df = generate_dataframe(X, chunks, self.inference_parameters)\n",
    "        else:\n",
    "            output_df = X.copy()\n",
    "            output_df[self.inference_parameters['output_column_name']] = chunks\n",
    "        \n",
    "        # Output\n",
    "        output = output_df.to_numpy()\n",
    "\n",
    "        return output"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting Model.py\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "afaf5eeb-6e54-4163-a964-7e916627ac6c",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "operator_id": "b742b6a9-f6dc-462e-8512-c01cdb668938",
  "task_id": "ebebc4e4-568d-4a42-98b2-afa395ed99b3"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}