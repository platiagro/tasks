{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  OCR (Optical Character Recognition) - Experimento\n",
    "## Utilização das bibliotecas [opencv](https://opencv.org/) e  [Tesseract OCR](https://tesseract-ocr.github.io/) para o reconhecimento de texto em imagens e da biblioteca [JiWER](https://github.com/jitsi/jiwer) para cálculo de mérticas de perfomance\n",
    "\n",
    "*   Mais detalhes sobre  o funcionamento dos algorítimos e das línguas nos quais o mesmo podem são utilizados são encontrados na [Tesseract documentation](https://tesseract-ocr.github.io/tessdoc/Data-Files)\n",
    "\n",
    "*   Caso seja passado um arquivo .xlsx com as strings de target pode visualizar a perfonrmance do algorítimo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "A variável `dataset` possui o caminho para leitura do arquivos importados na tarefa de \"Upload de dados\".<br>\n",
    "Você também pode importar arquivos com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "source": [
    "Para esse componente, a base de dados deve estar no seguinte formado:\n",
    "- Arquivo CSV chamado dataset.csv contendo as colunas \"image_path\", \"target\" e \"subset\", entre outras, caso necessário. Onde:\n",
    "    - image_path: caminho para o arquivo de imagem.\n",
    "    - target: resposta esperada da predição, caso exista.\n",
    "    - subset: conjunto ao qual a amostra faz parte, pode ser \"train\", \"test\", e \"val\". \n",
    "- Imagens coloridas (3 canais)\n",
    "- Cada conjunto de treino, validação e teste possuem sua pasta com suas respectivas imagens. Um exemplo da árvore de diretórios pode ser observado abaixo:\n",
    "\n",
    "```bash\n",
    "dataset\n",
    "|________dataset.csv\n",
    "|________train\n",
    "|        |__________image0.jpg\n",
    "|        |__________image1.jpg\n",
    "|        |__________image2.jpg\n",
    "|        |__________image3.jpg\n",
    "|               ...\n",
    "|\n",
    "|________val\n",
    "|        |__________image4.jpg\n",
    "|        |__________image5.jpg\n",
    "|        |__________image6.jpg\n",
    "|        |__________image7.jpg\n",
    "|               ...\n",
    "|\n",
    "|________test\n",
    "|        |__________image8.jpg\n",
    "|        |__________image9.jpg\n",
    "|        |__________image10.jpg\n",
    "|        |__________image11.jpg\n",
    "|              ...\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"/tmp/data/ocr.zip\" #@param {type:\"string\"}\n",
    "image_path = \"image_path\" #@param {type:\"string\", label:\"Caminho das imagens\", description:\"Coluna da tabela com o caminho para as imagens.\"}\n",
    "target = \"target\" #@param {type:\"string\", label:\"Atributo alvo\", description:\"Seu modelo tentará prever os valores do alvo.\"}\n",
    "\n",
    "#Hyperparams \n",
    "bbox_conf = 60 #@param {type:\"number\",label:\"Confiabilidade do bbox\", description:\"O quanto de confiabilidade o algorítmo deve possuir sobre o bbox para que o mesmo apareça.\"}\n",
    "\n",
    "#Pytesseact Params\n",
    "segmentation_mode = \"Considere um único bloco de texto uniforme\"  #@param [\"Orientação e detecção de script (OSD) apenas\",\"Segmentação automática de página com OSD\",\"Segmentação automática de página, mas sem OSD ou OCR\",\"Segmentação de página totalmente automática, mas sem OSD. (Padrão)\",\"Considere uma única coluna de texto de tamanhos variáveis\",\"Considere um único bloco uniforme de texto alinhado verticalmente\",\"Considere um único bloco de texto uniforme\",\"Trate a imagem como uma única linha de texto\",\"Trate a imagem como uma única palavra\",\"Trate a imagem como uma única palavra em um círculo\",\"Trate a imagem como um único caractere\",\"Texto esparso. Encontre o máximo de texto possível em nenhuma ordem específica\",\"Texto esparso com OSD\",\"Linha crua. Trate a imagem como uma única linha de texto, evitando hacks específicos do Tesseract\"] {type:\"string\",label:\"Modo de segmentação do PyTesseract\", description:\"Para mais informações acesse a documentação linkada no inicio do notebook\"}\n",
    "ocr_engine = \"Mecanismo de redes neurais com apenas LSTM\" #@param [\"Apenas mecanismo legado\",\"Mecanismo de redes neurais com apenas LSTM\",\"Mecanismo legado + LSTM\",\"Padrão, com base no que está disponível\"] {type:\"string\",label:\"Mecanismo OCR do Pytesseract\",description:\"Para mais informações acesse a documentação linkada no inicio do notebook\"}\n",
    "language = \"por\" #@param [\"por\",\"eng\"] {type:\"string\",label:\"Idioma pré teinado\",description:\"Opções disponibilizadas na aplicação compreendem português (por) e inglês (eng).\"}\n",
    "\n",
    "#Return formart\n",
    "bbox_return = \"np_array\" #@param [\"np_array\",\"image\"] {type:\"string\",label:\"Forma de retorno dos bboxes\",description:\"Escolher se bboxes serão retornados na imagem ou como um numpy array\"}\n",
    "image_return_format = \"N/A\" #@param [\"N/A\",\".jpg\",\".png\"] {type:\"string\",label:\"Formato de retorno da imagem caso bbox_return = image\",description:\"Escolher formato de retorno da imagem, N/A se retornar numpy array\"}\n",
    "remove_linebreaks = True #@param [True,False] {type:\"boolean\",label:\"Remove quebras de linha\",description:\"Caso True remove \\n e \\t dos resultados.Vale ressaltar que o texto de referência na tabela .xlsx caso haja, deve considerar este fato para calcular as métricas corretamente\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_segmentation = {\n",
    "    \"Orientação e detecção de script (OSD) apenas\" : \"Orientation and script detection (OSD) only.\",\n",
    "    \"Segmentação automática de página com OSD\" : \"Automatic page segmentation with OSD.\",\n",
    "    \"Segmentação automática de página, mas sem OSD ou OCR\" : \"Automatic page segmentation, but no OSD, or OCR.\",\n",
    "    \"Segmentação de página totalmente automática, mas sem OSD. (Padrão)\" : \"Fully automatic page segmentation, but no OSD. (Default)\",\n",
    "    \"Considere uma única coluna de texto de tamanhos variáveis\" : \"Assume a single column of text of variable sizes.\",\n",
    "    \"Considere um único bloco uniforme de texto alinhado verticalmente\" : \"Assume a single uniform block of vertically aligned text.\",\n",
    "    \"Considere um único bloco de texto uniforme\" : \"Assume a single uniform block of text.\",\n",
    "    \"Trate a imagem como uma única linha de texto\" : \"Treat the image as a single text line.\",\n",
    "    \"Trate a imagem como uma única palavra\" : \"Treat the image as a single word.\",\n",
    "    \"Trate a imagem como uma única palavra em um círculo\" : \"Treat the image as a single word in a circle.\",\n",
    "    \"Trate a imagem como um único caractere\" : \"Treat the image as a single character.\",\n",
    "    \"Texto esparso. Encontre o máximo de texto possível em nenhuma ordem específica\" : \"Sparse text. Find as much text as possible in no particular order.\",\n",
    "    \"Texto esparso com OSD\" : \"Sparse text with OSD\",\n",
    "    \"Linha crua. Trate a imagem como uma única linha de texto, evitando hacks específicos do Tesseract.\" : \"Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_mode = translate_segmentation[segmentation_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_engine = {\n",
    "    \"Apenas mecanismo legado\" : \"Legacy engine only.\",\n",
    "    \"Mecanismo de redes neurais com apenas LSTM\" : \"Neural nets LSTM engine only.\",\n",
    "    \"Mecanismo legado + LSTM\" : \"Legacy + LSTM engines.\",\n",
    "    \"Padrão, com base no que está disponível\" : \"Default, based on what is available.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_engine = translate_engine[ocr_engine]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso ao conjunto de dados\n",
    "\n",
    "O conjunto de dados utilizado nesta etapa será o mesmo carregado através da plataforma.<br>\n",
    "O tipo da variável retornada depende do arquivo de origem:\n",
    "- [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) para CSV e compressed CSV: .csv .csv.zip .csv.gz .csv.bz2 .csv.xz\n",
    "- [Binary IO stream](https://docs.python.org/3/library/io.html#binary-i-o) para outros tipos de arquivo: .jpg .wav .zip .h5 .parquet etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = dataset.split('.')[0]\n",
    "\n",
    "!mkdir -p {folder}\n",
    "!unzip -o {dataset} -d {folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(folder + '/dataset.csv')\n",
    "\n",
    "df[image_path] = folder + df[image_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de linhas com valores faltantes no atributo alvo\n",
    "Caso haja linhas em que o atributo alvo contenha valores faltantes, é feita a remoção dos casos faltantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) \n",
    "\n",
    "X = df[image_path].to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chamada da Classe de OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {'bbox_conf':bbox_conf}\n",
    "model_parameters = {'ocr_engine':ocr_engine,'segmentation_mode':segmentation_mode,'language':language}\n",
    "return_formats = {'bbox_return':bbox_return,'image_return_format':image_return_format, 'remove_linebreaks':remove_linebreaks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocr import Class_Pytesseract_OCR\n",
    "\n",
    "model = Class_Pytesseract_OCR(hyperparams, model_parameters,return_formats)\n",
    "df = model.get_result_dataframe(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from platiagro.plotting import plot_data_table\n",
    "\n",
    "ax = plot_data_table(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva métricas\n",
    "\n",
    "Utiliza a função `save_metrics` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar as métricas:`MER`, `WER`, `WIL`, `WIP` <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(MER=model.avg_mer, WER=model.avg_wer, WIL=model.avg_wil, WIP=model.avg_wip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva resultados da tarefa \n",
    "\n",
    "A plataforma guarda o conteúdo de `/tmp/data/` para as tarefas subsequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "artifacts = {\n",
    "    \"hyperparams\": hyperparams,\n",
    "    \"model_parameters\": model_parameters,\n",
    "    \"return_formats\":return_formats\n",
    "}\n",
    "\n",
    "dump(artifacts, \"/tmp/data/ocr.joblib\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "c11318b7-3905-4397-87bd-4b019b628a40",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "operator_id": "ddc6e842-4036-473a-951d-b30839179d78",
  "task_id": "f8e20efb-def0-4e1c-9927-9bf14214570a"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}