# -*- coding: utf-8 -*-
"""Copy of Experiment (16).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fMfyvT-gLkvmDANOH3KE4UyZDOBZS0uY
"""
import sys
sys.path.append('/home/rafaelcostaf/CPQD/tasks/tasks/insights')

import numpy as np
import pandas as pd
import statsmodels.api as sm
from scipy import stats
from insights.markdown_generator.report import Report

dataset = "data/amostra-siklee.xlsx" #@param

def decimal_converter(value):
        try:
            return float(value.replace(',', '.'))
        except ValueError:
            return value
        
        
class regression_analysis():
    
    numerical_cols = [
        'Tempo de Dispensa (dias)', 
        'Tempo de Entrega',
    ]
    features = [
        'Area de atuacao [Funcionario]',
        'Descricao do afastamento',
        "Especialidade medica",
    ]

    converter_dict = {col: decimal_converter for col in numerical_cols}

    #dataset = "Amostra_Siklee_Sem_Indetificacao_CPF.xlsx"

    df = pd.read_excel(dataset, index_col=None, header=0, converters=converter_dict)
    df_num = df[numerical_cols]

    df = df_num.join(df[features]).dropna(how='any')
    df = df.apply(lambda x: x.astype(str).str.upper())

    # as categóricas
    features = [
        'Area de atuacao [Funcionario]',
        "Especialidade medica",
    ]

    df_dummies = pd.get_dummies(df, prefix='', prefix_sep='', 
                                columns=features)
    df_dummies.head()

    import statsmodels.api as sm
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()


    df["Descricao do afastamento"] = label_encoder.fit_transform(df["Descricao do afastamento"])

    y = df["Descricao do afastamento"].to_numpy()
    X = df.drop("Descricao do afastamento", axis = 1).to_numpy()


    #y = label_encoder.fit_transform(y)
    #X = label_encoder.fit_transform(X)


    #mlogit_mod = sm.MNLogit(y, X)
    #mlogit_res = mlogit_mod.fit()
    #print(mlogit_res.summary())

    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()

    df_dummies["Descricao do afastamento"] = label_encoder.fit_transform(df_dummies["Descricao do afastamento"])

    y = df_dummies["Descricao do afastamento"].to_numpy()
    X = df_dummies.drop("Descricao do afastamento", axis = 1).to_numpy()

    from sklearn.linear_model import LogisticRegression

    clf = LogisticRegression(multi_class='multinomial',solver='newton-cg')
    y_dummie = pd.get_dummies(df['Descricao do afastamento'])

    model = clf.fit(X,y)

    col_labels = df_dummies.drop("Descricao do afastamento", axis = 1).columns
    print(col_labels)
    df["Especialidade medica"].nunique()

    """## Linkando coreficiente com parâmero

    Aqui vai partir o textinho e odds

    Para análise destes dados utilizo o modelo de regressão logística politômica com o afastamentos causados por Sintomas, sinais e achados anormais
    como baseline para as proporções estimadas para cada causa de afastamento, assim podemos comparar facilmente as
    chances de algum afastamento versus o Sintomas, sinais e achados anormais.

    Colocando no schema
    """

    label = label_encoder.inverse_transform(model.classes_)

    data = dict(zip(label, model.coef_))
    #data
    next(iter(data.items()))

    target = 'Descricao do afastamento'
    col_labels = df_dummies.drop(target, axis = 1).columns
    col_labels[[1, 2, 3]]

    def get_top_n(dict, n = 5):
        for key, value in dict.items():
            
            inx = value.argsort()[:n]
            
            classe_max_feature = col_labels[[inx[0]]][0]
            
            porcentagem = round(np.exp(value[inx[0]]), 3)*100

            print(f"Temos que para a classe {key} de {target} casos com {classe_max_feature} são {porcentagem}% mais provaveis \n")
            
        return
    
    get_top_n(data)

    def report_begin(self, ):
      
        # Report #
        report = Report('Relatório Regressão Logistica CPQD')
        
        schema = {'section_title': 'Analise de probabilidade de cada categoria', 'information': []}
            
        schema['information'].append(
        
            dict(
                type='text',
                info="""
                Para análise destes dados utilizo o modelo de regressão logística politômica com o afastamentos causados por Sintomas, sinais e achados anormais
                como baseline para as proporções estimadas para cada causa de afastamento, assim podemos comparar facilmente as
                chances de algum afastamento versus o Sintomas, sinais e achados anormais."""  
            )  
        )
        
        return schema, report    