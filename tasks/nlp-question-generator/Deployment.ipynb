{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generator - Implantação\n",
    "\n",
    "Utiliza um transformer T5 pré treinado em português e disponibilizado pelo [huggingfaces](https://platiagro.github.io/tutorials/).<br>\n",
    "\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de Classe para Predições em Tempo Real\n",
    "\n",
    "A tarefa de implantação cria um serviço REST para predições em tempo-real.<br>\n",
    "Para isso você deve criar uma classe `Model` que implementa o método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Model.py\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from expander import DocExpander\n",
    "from aux_functions import build_df_result\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loaded = False\n",
    "        \n",
    "        \n",
    "    def load(self):\n",
    "        \n",
    "        artifacts = joblib.load(\"/tmp/data/qgenerator.joblib\")\n",
    "        self.model = artifacts[\"model\"]\n",
    "        self.expand_context = artifacts[\"expand_context\"]\n",
    "        self.infer_num_gen_sentences = artifacts[\"infer_num_gen_sentences\"]\n",
    "        self.column_context = artifacts[\"column_context\"]\n",
    "        self.column_question = artifacts[\"column_question\"]\n",
    "        self.loaded = True\n",
    "\n",
    "    def class_names(self) -> List:\n",
    "        return ['doc_id','context','questions','expanded_context']\n",
    "    \n",
    "    def expand(self,df):\n",
    "        if self.expand_context:\n",
    "            exp = DocExpander() \n",
    "            df_final = exp.expand_sql(df,context_column_name=self.column_context,questions_column_name = self.column_question)\n",
    "        \n",
    "        return df_final\n",
    "\n",
    "    def predict(self, X, feature_names, meta=None):\n",
    "        \n",
    "        if not self.loaded:\n",
    "            self.load()\n",
    "            \n",
    "        feature_names_pipeline = ['doc_id', 'context']\n",
    "        feature_names_qa = ['context']\n",
    "        \n",
    "        if feature_names != feature_names_pipeline and feature_names != feature_names_qa:\n",
    "            raise ValueError(f'feature_names deve ser {feature_names_pipeline} ou {feature_names_qa}')\n",
    "        \n",
    "        \n",
    "        df_input = pd.DataFrame(X,columns=feature_names)\n",
    "        contexts = df_input['context'].to_numpy()\n",
    "        gen_questions_dict = self.model.forward(contexts=contexts, num_gen_sentences=self.infer_num_gen_sentences)\n",
    "        df_result = build_df_result(gen_questions_dict,column_context=self.column_context,column_question=self.column_question)\n",
    "        df_result = self.expand(df_result)\n",
    "        \n",
    "        if feature_names == feature_names_pipeline:\n",
    "            df_input = df_input[['doc_id']] \n",
    "            df_input['index'] = df_input.index\n",
    "            df_result['index'] = df_result.index\n",
    "            df_result = pd.merge(df_input, df_result, on='index', how='outer')\n",
    "            del df_result['index']\n",
    "            \n",
    "        return df_result.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"squad-test-v1.1.csv\")\n",
    "# n_lines = 10\n",
    "# contexts = df['context'][:n_lines]\n",
    "# indexes = df.index[:n_lines]\n",
    "\n",
    "# df_small = pd.DataFrame({'doc_id':indexes,'context':contexts})\n",
    "# X = df_small.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Model import Model\n",
    "# model = Model()\n",
    "# result = model.predict(X,['doc_id','context'])\n",
    "# result"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "dd63cfbd-7a97-41ac-bd9b-fd11711ba459",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "operator_id": "e4150bc8-88f2-4d98-b68a-6c246270c403",
  "task_id": "ccfeb3fe-3d3a-43cf-bdc4-d0b07017e468"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
