{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generator - Experimento\n",
    "\n",
    "Utiliza um transformer T5 pré treinado em português e disponibilizado pelo [huggingfaces](https://platiagro.github.io/tutorials/).<br>\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "A variável `dataset` possui o caminho para leitura do arquivos importados na tarefa de \"Upload de dados\".<br>\n",
    "Você também pode importar arquivos com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"/tmp/data/reports_contexts-9.csv\" #@param {type:\"string\"}\n",
    "\n",
    "### Dados para Treinamento\n",
    "\n",
    "# Dataset\n",
    "column_context = \"context\" #@param [\"context\"] {type:\"string\",label:\"Coluna contexto\",description:\"Coluna em que estão contidas os contextos\"}\n",
    "column_question = \"questions\" #@param {type:\"string\",label:\"Coluna pergunta\",description:\"Coluna em que estão contidas listas de perguntas por células. Apenas considerada se train_from_zero=True\"}\n",
    "train_from_zero = False #@param {type:\"boolean\",label:\"Treinamento do algorítimo do zero\",description:\"Caso True utiliza o algorítimo com finne-tunning no squad em português. Caso True retreina do zero\"}\n",
    "train_from_squad = False #@param {type:\"boolean\",label:\"Treinamento do algorítimo pelo Sqaud\",description:\"Caso True utiliza treinará algorítimo com finne-tunning no squad em português. Caso False teinará com o dataset passado\"}\n",
    "\n",
    "#prepare_data\n",
    "dev_size_from_data= 0.2 #@param {type:\"float\",label:\"Porcentagem para avaliação\",description:\"Parcela dos dados utilizadas para avaliação, sendo o restante utilizado para treino. Apenas considerada se train_from_zero=True e train_from_squad=True\"}\n",
    "test_size_from_dev= 0.5 #@param {type:\"float\",label:\"Porcentagem para teste\",description:\"Parcela dos dados utilizadas para avaliação que serã utilizados para teste, sendo o restante utilizado para validação. Apenas considerada se train_from_zero=True\"}\n",
    "#batch_dataset_preparation = 30 #@param {type:\"float\",label:\"Batch para preparação dos dados\",description:\"Tamanho do batchque o tokenizador utilizará para preparar o dataset. Apenas considerada se train_from_zero=True\"}\n",
    "\n",
    "model_name = \"unicamp-dl/ptt5-base-portuguese-vocab\" #@param {type:\"string\",label:\"Modelo\",description:\"Modelo utilizado da base de modelo do hugginfaces\"}\n",
    "PREFIX = \"gerador_perguntas:\" #@param {type:\"string\",label:\"Prefixo para o T5\",description:\"Incluindo em cada sentença passada ao transformers. Apenas considerado se train_from_zero=True\"}\n",
    "num_gen_sentences: 2 #@param {type:\"integer\",label:\"Número de perguntas geradas experimentação\",description:\"Apenas consideradao se train_from_zero=True\"}\n",
    "infer_num_gen_sentences: 10 #@param {type:\"integer\",label:\"Número de perguntas geradas na inferência\"}\n",
    "train_batch_size= 2 #@param {type:\"integer\",label:\"Batch size para treino\",description:\"Tamanho do batch de treino. Está associado a num_gen_sentences. Apenas considerado se train_from_zero=True\"}\n",
    "eval_batch_size= 32 #@param {type:\"integer\",label:\"Batch size para avaliação\",description:\"Tamanho do batch de validação e teste. Está associado a num_gen_sentences. Apenas considerado se train_from_zero=True\"}\n",
    "infer_batch_size = 16  #@param {type:\"integer\",label:\"Batch size para inferência\"}\n",
    "no_repeat_ngram_size= 2 #@param {type:\"float\",label:\"Sequência máxima de tokens repetidos\",description:\"Após a repetição de tokens configurada, força a trocar de token na geração do decoder\"}\n",
    "temperature= 0.7 #@param {type:\"float\",label:\"Temperatura de randomização do decoder\",description:\"Pode ser entre 0 e 1. Quanto mais próxima de 0, mais próximo da decodificação gulosa (que procura tokens de maior probabilidade), quanto mais próximo de 1 randomiza entre os tokens contidos no top_p\"}\n",
    "top_p= 0.92 #@param {type:\"float\",label:\"Porcentagem de consideração\",description:\"Considera apenas os tokens que compoẽ a porcentagem top_op no histograma de probabilidades dos tokens de saída https://huggingface.co/blog/how-to-generate\"}\n",
    "source_max_length= 512 #@param {type:\"integer\",label:\"Tamanho do contexto de entrada\",description:\"Tamanho máximo contexto de entrada em tokens\"}\n",
    "target_max_length= 100 #@param {type:\"integer\",label:\"Tamanho da sentença gerada\",description:\"Tamanho máximo da pergunta derada em tokens\"}\n",
    "learning_rate= 3.0e-5 #@param {type:\"float\",label:\"Taxa de aprendizado\"}\n",
    "eps= 1.0e-08 #@param {type:\"integer\",float:\"Valor de estabilidade do otimizador Adam\"}\n",
    "seed = 13 #@param {type:\"integer\",label:\"Semente de aleatoriedade\"}\n",
    "\n",
    "#lightning_params\n",
    "num_gpus= 1 #@param {type:\"integer\",label:\"Numero de GPUs\"}\n",
    "profiler= True #@param {type:\"integer\",label:\"Resumo\"}\n",
    "max_epochs= 1 #@param {type:\"integer\",label:\"Máximo de épocas para treinamento\"}\n",
    "accumulate_grad_batches= 16 #@param {type:\"integer\",label:\"Batchs acumulados\",description:\"Batchs acumulados antes de atualizar os pesos\"}\n",
    "check_val_every_n_epoch= 1 #@param {type:\"integer\",label:\"Frequência Validação\",description:\"Frequência da chamada da validação em épocas\"}\n",
    "progress_bar_refresh_rate= 1 #@param {type:\"integer\",label:\"Frequência de autuazaliação da barra de progresso\"}\n",
    "gradient_clip_val= 1.0 #@param {type:\"float\",label:\"Favor de corte dos gradientes\",\"description\":\"O fator evita que os gradientes explodam definindo um limite para os mesmos\"}\n",
    "fast_dev_run= False #@param {type:\"boolean\",label:\"Rodar um batch\",description:\"Utilizado para validar que todas as partes estão funcionando antes de treinar o modelo por inteiro\"}\n",
    "\n",
    "#early_stop_callback\n",
    "monitor= 'avg_train_loss' #@param {type:\"integer\",label:\"Frequência de autuazaliação da barra de progresso\"}\n",
    "min_delta= 0.01 #@param {type:\"integer\",label:\"Variação mínima entre épocas\"}\n",
    "patience= 1 #@param {type:\"integer\",label:\"Epera após atingir variação mínima\"}\n",
    "verbose= False #@param {type:\"boolean\",label:\"Disponibilizar informações early stop\"}\n",
    "mode= 'min' #@param [\"min\",\"max\"] {type:\"integer\",label:\"Modo de parada\",description: \"Modo de funcionamento para critério de parada\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura do conjunto de dados\n",
    "\n",
    "O exemplo abaixo faz a leitura de dados tabulares (ex: .csv).<br>\n",
    "Modifique o código de acordo com o tipo de dado que desejar ler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"context\" not in df.columns:\n",
    "    raise ValueError(\"A coluna context deve estar obrigatoramente contida no dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_result(gen_questions_dict):\n",
    "    df_result = pd.DataFrame({'context': gen_questions_dict[\"context\"],'questions_list': gen_questions_dict[\"questions\"]})\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset em subconjuntos de treino, validação e teste\n",
    "\n",
    "Subconjunto de treino: amostra de dados usada para treinar o modelo.<br>\n",
    "Subconjunto de treino: amostra de dados usada para validar o modelo.<br>\n",
    "Subconjunto de teste: amostra de dados usada para fornecer uma avaliação imparcial do treinamento do modelo no subconjunto de dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "if (train_from_zero and not train_from_squad):\n",
    "    df_train,df_ = train_test_split(df, train_size=dev_size_from_data)\n",
    "    df_valid, df_test = train_test_split(df_, train_size=test_size_from_dev)\n",
    "    train_output = 'df_squad_train_bert_chuncked.csv'\n",
    "    valid_output = 'df_squad_valid_bert_chuncked.csv'\n",
    "    test_output =  'df_squad_test_bert_chuncked.csv'\n",
    "    df_train.to_csv(os.path.join(train_output),index=False)\n",
    "    df_valid.to_csv(os.path.join(valid_output),index=False)\n",
    "    df_test.to_csv(os.path.join(test_output),index=False)\n",
    "else:\n",
    "    df_test = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando Argumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeando dirpaths\n",
    "import os\n",
    "data_dir  =  root_dir = os.getcwd()\n",
    "logs_dir = os.path.join(root_dir,\"lightning_logs\")\n",
    "# Colocando parâmetros de entrada no fromato esperado\n",
    "hparams = {\n",
    "    \"model_name\":model_name,\n",
    "    \"PREFIX\":PREFIX,\n",
    "    \"save_every\":save_every,\n",
    "    \"num_gen_sentences\":num_gen_sentences,\n",
    "    \"infer_num_gen_sentences\":infer_num_gen_sentences,\n",
    "    \"no_repeat_ngram_size\":no_repeat_ngram_size,\n",
    "    \"temperature\":temperature,\n",
    "    \"top_p\":top_p,\n",
    "    \"train_batch_size\":train_batch_size,\n",
    "    \"eval_batch_size\":eval_batch_size,\n",
    "    \"infer_batch_size\":infer_batch_size,\n",
    "    \"source_max_length\":source_max_length,\n",
    "    \"target_max_length\":target_max_length,\n",
    "    \"learning_rate\":learning_rate,\n",
    "    \"eps\":eps,\n",
    "    \"seed\":seed,\n",
    "}\n",
    "\n",
    "lightning_params = {\n",
    "    \"num_gpus\":num_gpus,\n",
    "    \"profiler\":profiler,\n",
    "    \"max_epochs\":max_epochs,\n",
    "    \"accumulate_grad_batches\":accumulate_grad_batches,\n",
    "    \"check_val_every_n_epoch\":check_val_every_n_epoch,\n",
    "    \"progress_bar_refresh_rate\":progress_bar_refresh_rate,\n",
    "    \"gradient_clip_val\":gradient_clip_val,\n",
    "    \"fast_dev_run\":fast_dev_run,\n",
    "}\n",
    "\n",
    "early_stop_callback_params = {\n",
    "     \"monitor\":monitor,\n",
    "    \"min_delta\":min_delta,\n",
    "    \"patience\":patience,\n",
    "    \"verbose\":verbose,\n",
    "    \"mode\":mode,    \n",
    "}\n",
    "\n",
    "prepare_data_params = {\n",
    "     #\"batch_dataset_preparation\":batch_dataset_preparation,\n",
    "     \"test_size_from_dev\":test_size_from_dev,\n",
    "}\n",
    "\n",
    "# Configurações\n",
    "config = {'params':{'hparams':hparams,\n",
    "                    'lightning_params':lightning_params,\n",
    "                    'early_stop_callback_params':early_stop_callback_params,\n",
    "                    'prepare_data_params':prepare_data_params },\n",
    "\n",
    "        'dirpaths':{'data_dirpath':data_dir,\n",
    "                'log_dirpath':logs_dir,\n",
    "                'cwd_dirpath':root_dir},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Zero / Recuperação dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from caller import Qgenerator_caller\n",
    "\n",
    "# Criando Caller\n",
    "qgenerator_caller = Qgenerator_caller(config)\n",
    "\n",
    "#Fazendo Build\n",
    "qgenerator_caller.build()\n",
    "\n",
    "if train_from_zero:\n",
    "        \n",
    "    #Preparando dados\n",
    "    if train_from_squad:\n",
    "        squad_train_path = os.path.join(data_dir,'squad-train-v1.1.json')\n",
    "        squad_dev_path= os.path.join(data_dir,'squad-dev-v1.1.json')\n",
    "        \n",
    "        prepared_datapaths = qgenerator_caller.prepare_data(squad_train_path=squad_train_path,\n",
    "                                                        squad_dev_path=squad_dev_path)\n",
    "    else:\n",
    "        \n",
    "        prepared_datapaths = {\n",
    "                                'prepared_data_train_path':train_output,\n",
    "                                 'prepared_data_valid_path':valid_output,\n",
    "                                 'prepared_data_test_path':test_output\n",
    "                             }\n",
    "    \n",
    "    \n",
    "    # Treinamento\n",
    "    _ = qgenerator_caller.train(train_path=prepared_datapaths['prepared_data_train_path'],\n",
    "                            valid_path=prepared_datapaths['prepared_data_valid_path'],\n",
    "                            test_path=prepared_datapaths['prepared_data_test_path'])\n",
    "    \n",
    "    MODEL_PATH = \"trained_model.ckpt\"\n",
    "    qgenerator_caller.save_checkpoint(MODEL_PATH)\n",
    "    \n",
    "    # Avaliação\n",
    "    qgenerator_caller.evaluate()\n",
    "else:\n",
    "    MODEL_PATH = \"default_qgenerator_squad_pt.ckpt\"\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        !wget -nc https://storage.googleapis.com/platiagro/Vident/default_qgenerator_squad_pt.ckpt\n",
    "    \n",
    "    qgenerator_caller.load_model(checkpoint_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando as perguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = df_test['context'].to_numpy()\n",
    "gen_questions_dict = qgenerator_caller.forward(contexts=contexts, num_gen_sentences=infer_num_gen_sentences)\n",
    "df_result = build_df_result(gen_questions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(dataset, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva resultados da tarefa\n",
    "\n",
    "A plataforma guarda o conteúdo de `/tmp/data/` para as tarefas subsequentes.<br>\n",
    "Use essa pasta para salvar modelos, metadados e outros resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "artifacts = {\n",
    "    \"model\":qgenerator_caller,\n",
    "}\n",
    "\n",
    "dump(artifacts, \"/tmp/data/qgenerator_caller.joblib\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "dd63cfbd-7a97-41ac-bd9b-fd11711ba459",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "operator_id": "e4150bc8-88f2-4d98-b68a-6c246270c403",
  "task_id": "ccfeb3fe-3d3a-43cf-bdc4-d0b07017e468"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}