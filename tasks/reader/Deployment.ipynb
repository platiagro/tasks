{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader - Implantação\n",
    "\n",
    "Este componente utiliza um modelo de QA pré-treinado em Português com o dataset SQuAD v1.1, é um modelo de domínio público disponível em [Hugging Face](https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese).<br>\n",
    "\n",
    "Seu objetivo é encontrar a resposta de uma ou mais perguntas de acordo com uma lista de contextos distintos.\n",
    "\n",
    "A tabela de dados de entrada deve possuir uma coluna de contextos, em que cada linha representa um contexto diferente, e uma coluna de perguntas em que cada linha representa uma pergunta a ser realizada. Note que para cada pergunta serão utilizados todos os contextos fornecidos para realização da inferência, e portanto, podem haver bem mais contextos do que perguntas.\n",
    "\n",
    "Obs: Este componente utiliza recursos da internet, portanto é importante estar conectado à rede para que este componente funcione corretamente.<br>\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de Classe para Predições em Tempo Real\n",
    "\n",
    "A tarefa de implantação cria um serviço REST para predições em tempo-real.<br>\n",
    "Para isso você deve criar uma classe `Model` que implementa o método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Model.py\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from reader import Reader\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.loaded = False\n",
    "\n",
    "    def load(self):\n",
    "        \n",
    "        # Load artifacts\n",
    "        artifacts = joblib.load(\"/tmp/data/reader.joblib\")\n",
    "        self.model_parameters = artifacts[\"model_parameters\"]\n",
    "        self.inference_parameters = artifacts[\"inference_parameters\"]\n",
    "        \n",
    "        # Initialize reader\n",
    "        self.reader = Reader(**self.model_parameters)\n",
    "        \n",
    "        # Set model loaded\n",
    "        self.loaded = True\n",
    "        print(\"Loaded model\")\n",
    "    \n",
    "    def class_names(self):\n",
    "        column_names = list(self.inference_parameters['output_columns'])\n",
    "        return column_names\n",
    "\n",
    "    def predict(self, X, feature_names, meta=None):\n",
    "        if not self.loaded:\n",
    "            self.load()\n",
    "            \n",
    "        # Convert to dataframe\n",
    "        if feature_names != []:\n",
    "            df = pd.DataFrame(X, columns = feature_names)\n",
    "            df = df[self.inference_parameters['input_columns']]\n",
    "        else:\n",
    "            df = pd.DataFrame(X, columns = self.inference_parameters['input_columns'])\n",
    "            \n",
    "        # Predict answers #\n",
    "\n",
    "        # Iterate over dataset\n",
    "        for idx, row in df.iterrows():\n",
    "\n",
    "            # Get question\n",
    "            question = row[self.inference_parameters['question_column_name']]\n",
    "\n",
    "            # Get context\n",
    "            context = row[self.inference_parameters['context_column_name']]\n",
    "\n",
    "            # Make prediction\n",
    "            answer, probability, _ = self.reader([question], [context])\n",
    "\n",
    "            # Save to df\n",
    "            df.at[idx, self.inference_parameters['answer_column_name']] = answer[0]\n",
    "            df.at[idx, self.inference_parameters['proba_column_name']] = probability[0]\n",
    "\n",
    "        # Retrieve Only Best Answer #\n",
    "\n",
    "        # Initializate best df\n",
    "        best_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "        # Get unique questions\n",
    "        unique_questions = df[self.inference_parameters['question_column_name']].unique()\n",
    "\n",
    "        # Iterate over each unique question\n",
    "        for question in unique_questions:\n",
    "\n",
    "            # Filter df\n",
    "            question_df = df[df[self.inference_parameters['question_column_name']] == question]\n",
    "\n",
    "            # Sort by score (descending)\n",
    "            question_df = question_df.sort_values(by=self.inference_parameters['proba_column_name'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "            # Append best ansewer to output df\n",
    "            best_df = pd.concat((best_df,pd.DataFrame(question_df.loc[0]).T)).reset_index(drop=True)\n",
    "            \n",
    "        if self.inference_parameters['keep_best'] == 'sim':\n",
    "            return best_df.values\n",
    "        else:\n",
    "            return df.values"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "bf343db5-c377-4193-83bf-ba9545fb56d2",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "operator_id": "e9796980-5128-4c0c-a28e-81e4b68738fd",
  "task_id": "f2692fcb-7990-499a-8c20-9aa59b9629cf"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
