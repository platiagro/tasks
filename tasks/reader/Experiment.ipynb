{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader - Experimento\n",
    "\n",
    "Este componente utiliza um modelo de QA pré-treinado em Português com o dataset SQuAD v1.1, é um modelo de domínio público disponível em [Hugging Face](https://huggingface.co/pierreguillou/bert-large-cased-squad-v1.1-portuguese).<br>\n",
    "\n",
    "Seu objetivo é encontrar a resposta de uma ou mais perguntas de acordo com uma lista de contextos distintos.\n",
    "\n",
    "A tabela de dados de entrada deve possuir uma coluna de contextos, em que cada linha representa um contexto diferente, e uma coluna de perguntas em que cada linha representa uma pergunta a ser realizada. Note que para cada pergunta serão utilizados todos os contextos fornecidos para realização da inferência, e portanto, podem haver bem mais contextos do que perguntas.\n",
    "\n",
    "Obs: Este componente utiliza recursos da internet, portanto é importante estar conectado à rede para que este componente funcione corretamente.\n",
    "\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "A variável `dataset` possui o caminho para leitura do arquivos importados na tarefa de \"Upload de dados\".<br>\n",
    "Você também pode importar arquivos com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"/tmp/data/simple_q&a-12.csv\" #@param {type:\"string\"}\n",
    "context_column_name = \"text\" #@param {type:\"string\", label:\"Coluna dos contextos\", description:\"Esta coluna será utilizada para ler os contextos e aplicar o Reader.\"}\n",
    "question_column_name = \"question\" #@param {type:\"string\", label:\"Coluna das perguntas\", description:\"Esta coluna será utilizada para identificar as perguntas a serem aplicadas aos contextos.\"}\n",
    "answer_column_name = \"answer\" #@param {type:\"string\", label:\"Coluna das respostas\", description:\"Esta coluna será utilizada para gerar a resposta produzida por cada pergunta.\"}\n",
    "proba_column_name = \"answer_score\" #@param {type:\"string\", label:\"Coluna da pontuação das respostas\", description:\"Esta coluna será utilizada para gerar a pontuação de cada resposta produzida.\"}\n",
    "expected_column_name = \"\" #@param {type:\"string\", label:\"Coluna de avaliação\", description:\"Esta coluna será utilizada para avaliar as respostas produzidas por cada pergunta, espera-se que nesta coluna estejam as respostas esperadas de cada pergunta em sua respectiva linha na tabela. É uma coluna opcional.\"}\n",
    "device = \"cpu\" #@param [\"cuda\",\"cpu\"] {type:\"string\",multiple:false,label:\"Dispositivo\",description:\"Tipo de dispositivo para utilizar o componente.\"}\n",
    "keep_best = \"sim\" #@param [\"sim\",\"não\"] {type:\"string\",multiple:false,label:\"Apenas Melhor Resposta\",description:\"Manterá apenas as linhas correspondentes à melhor resposta gerada pelo par pergunta e contexto.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura do conjunto de dados\n",
    "\n",
    "O exemplo abaixo faz a leitura de dados tabulares (ex: .csv).<br>\n",
    "Modifique o código de acordo com o tipo de dado que desejar ler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>expected_retriever_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A bola é um objeto utilizado para lazer de uma...</td>\n",
       "      <td>Qual o formato da bola?</td>\n",
       "      <td>esférica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Golfe é um esporte no qual os jogadores usam d...</td>\n",
       "      <td>Qual o formato da bola?</td>\n",
       "      <td>esférica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jogo por tacadas[1] (stroke play[2]), também c...</td>\n",
       "      <td>Qual o formato da bola?</td>\n",
       "      <td>esférica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A bola é um objeto utilizado para lazer de uma...</td>\n",
       "      <td>Aonde se pratica golfe?</td>\n",
       "      <td>campo de golfe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Golfe é um esporte no qual os jogadores usam d...</td>\n",
       "      <td>Aonde se pratica golfe?</td>\n",
       "      <td>campo de golfe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Jogo por tacadas[1] (stroke play[2]), também c...</td>\n",
       "      <td>Aonde se pratica golfe?</td>\n",
       "      <td>campo de golfe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  \\\n",
       "0      1  A bola é um objeto utilizado para lazer de uma...   \n",
       "1      2  Golfe é um esporte no qual os jogadores usam d...   \n",
       "2      3  Jogo por tacadas[1] (stroke play[2]), também c...   \n",
       "3      1  A bola é um objeto utilizado para lazer de uma...   \n",
       "4      2  Golfe é um esporte no qual os jogadores usam d...   \n",
       "5      3  Jogo por tacadas[1] (stroke play[2]), também c...   \n",
       "\n",
       "                  question expected_answer  expected_retriever_answer  \n",
       "0  Qual o formato da bola?        esférica                          1  \n",
       "1  Qual o formato da bola?        esférica                          1  \n",
       "2  Qual o formato da bola?        esférica                          1  \n",
       "3  Aonde se pratica golfe?  campo de golfe                          2  \n",
       "4  Aonde se pratica golfe?  campo de golfe                          2  \n",
       "5  Aonde se pratica golfe?  campo de golfe                          2  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteúdo da tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert parameters\n",
    "\n",
    "assert context_column_name in df.columns, f\"Coluna '{context_column_name}' deve ser uma coluna do dataset.\"\n",
    "assert question_column_name in df.columns, f\"Coluna '{question_column_name}' deve ser uma coluna do dataset.\"\n",
    "assert answer_column_name not in df.columns and answer_column_name != \"\", f\"Coluna '{answer_column_name}' não pode ser vazia e nem uma coluna do dataset.\"\n",
    "assert proba_column_name not in df.columns and proba_column_name != \"\", f\"Coluna '{proba_column_name}' não pode ser vazia e nem uma coluna do dataset.\"\n",
    "assert expected_column_name == \"\" or expected_column_name in df.columns, f\"Coluna '{expected_column_name}' deve ser uma coluna do dataset ou deixar ou campo em branco.\"\n",
    "assert device in ['cuda', 'cpu'], f\"Dispositivo '{device}' deve ser ou 'cuda' ou 'cpu'.\"\n",
    "assert keep_best in ['sim', 'não'], f\"Apenas Melhor Resposta deve ser ou 'sim' ou 'não'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# Model parameters\n",
    "model_parameters = {\n",
    "    'device':torch.device(device) if torch.cuda.is_available() else torch.device('cpu'),\n",
    "}\n",
    "    \n",
    "# Inference parameters\n",
    "inference_parameters = {\n",
    "    'context_column_name':context_column_name,\n",
    "    'question_column_name':question_column_name,\n",
    "    'expected_column_name':expected_column_name,\n",
    "    'answer_column_name':answer_column_name,\n",
    "    'proba_column_name':proba_column_name,\n",
    "    'input_columns': list(df.columns),\n",
    "    'output_columns': list(df.columns) + [answer_column_name, proba_column_name],\n",
    "    'keep_best': keep_best\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24516331152447c9da0424641b5b3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/918 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66629a1ccf643468fa10d2c5ba1ced3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07463c4876948db91aa9adfe8f97f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f21cc09a584bddb177ba570c3cce01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/210k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69602aaa3404c57ae55f9d8d59a6a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from reader import Reader\n",
    "\n",
    "# Initilizate Reader\n",
    "reader = Reader(**model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict answers #\n",
    "\n",
    "# Iterate over dataset\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    # Get question\n",
    "    question = row[inference_parameters['question_column_name']]\n",
    "    \n",
    "    # Get context\n",
    "    context = row[inference_parameters['context_column_name']]\n",
    "        \n",
    "    # Make prediction\n",
    "    answer, probability, _ = reader([question], [context])\n",
    "    \n",
    "    # Save to df\n",
    "    df.at[idx, inference_parameters['answer_column_name']] = answer[0]\n",
    "    df.at[idx, inference_parameters['proba_column_name']] = probability[0]\n",
    "    \n",
    "# Retrieve Only Best Answer #\n",
    "\n",
    "# Initializate best df\n",
    "best_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# Get unique questions\n",
    "unique_questions = df[inference_parameters['question_column_name']].unique()\n",
    "\n",
    "# Iterate over each unique question\n",
    "for question in unique_questions:\n",
    "\n",
    "    # Filter df\n",
    "    question_df = df[df[inference_parameters['question_column_name']] == question]\n",
    "\n",
    "    # Sort by score (descending)\n",
    "    question_df = question_df.sort_values(by=inference_parameters['proba_column_name'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Append best ansewer to output df\n",
    "    best_df = pd.concat((best_df,pd.DataFrame(question_df.loc[0]).T)).reset_index(drop=True)\n",
    "\n",
    "del reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "if inference_parameters['keep_best'] == 'sim':\n",
    "    best_df.to_csv(dataset, index=False)\n",
    "else:\n",
    "    df.to_csv(dataset, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.metrics_nlp import wrapper\n",
    "from platiagro.plotting import plot_data_table\n",
    "# Evaluate translation (Optional)\n",
    "\n",
    "# Iff is not empty\n",
    "if inference_parameters['expected_column_name'] != \"\":\n",
    "    \n",
    "    # Initializate calculator\n",
    "    calculator = wrapper.MetricsCalculator(metrics=['bleu', 'rouge'])\n",
    "    \n",
    "    # Get expected/predicted answers\n",
    "    y_true = list(best_df[inference_parameters['expected_column_name']].values)\n",
    "    y_pred = list(best_df[inference_parameters['answer_column_name']].values)\n",
    "    \n",
    "    # Perform calculations\n",
    "    scores = calculator.calculate_from_texts(\n",
    "        y_pred, \n",
    "        y_true\n",
    "    )\n",
    "    \n",
    "    # Plot metrics\n",
    "    plot_data_table(pd.DataFrame(scores, index = ['Valor']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva resultados da tarefa\n",
    "\n",
    "A plataforma guarda o conteúdo de `/tmp/data/` para as tarefas subsequentes.<br>\n",
    "Use essa pasta para salvar modelos, metadados e outros resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/data/reader.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "artifacts = {\n",
    "    \"model_parameters\": model_parameters,\n",
    "    \"inference_parameters\": inference_parameters\n",
    "}\n",
    "\n",
    "dump(artifacts, \"/tmp/data/reader.joblib\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "bf343db5-c377-4193-83bf-ba9545fb56d2",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "operator_id": "e9796980-5128-4c0c-a28e-81e4b68738fd",
  "task_id": "f2692fcb-7990-499a-8c20-9aa59b9629cf"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
