{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoKeras AutoCV  - Experimento\n",
    "\n",
    "Este componente utiliza [AutoKeras](https://autokeras.com/) AutoCV para a tarefa de classificação.     \n",
    "O algoritmo faz a busca por arquiteturas e hyperparâmetros que melhor configuram o modelo\n",
    "para a base de dados fornecida.\n",
    "\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "A variável `dataset` possui o caminho para leitura do arquivos importados na tarefa de \"Upload de dados\".<br>\n",
    "Você também pode importar arquivos com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esse componente, a base de dados deve estar no seguinte formado:\n",
    "- Imagens coloridas (3 canais) no formato 256x256 pixels. Caso não estejam nesse formato, o código faz as alterações necesssárias\n",
    "- Cada classe tem sua pasta com suas respectivas imagens, além dos conjuntos de treino, validação e teste terem suas pastas separadas. Um exemplo da árvore de diretórios pode ser observado abaixo:\n",
    "\n",
    "```bash\n",
    "dataset\n",
    "|________train\n",
    "|        |_____class_name1\n",
    "|        |     |____image0.jpg\n",
    "|        |     |____image1.jpg\n",
    "|        |     ...\n",
    "|        |\n",
    "|        |_____class_name2\n",
    "|              |____image3.jpg\n",
    "|              |____image4.jpg\n",
    "|               ...\n",
    "|________val\n",
    "|        |_____class_name1\n",
    "|        |     |____image5.jpg\n",
    "|        |     |____image6.jpg\n",
    "|        |     ...\n",
    "|        |\n",
    "|        |_____class_name2\n",
    "|              |____image7.jpg\n",
    "|              |____image8.jpg\n",
    "|               ...\n",
    "|________test\n",
    "|        |_____class_name1\n",
    "|        |     |____image9.jpg\n",
    "|        |     |____image10.jpg\n",
    "|        |     ...\n",
    "|        |\n",
    "|        |_____class_name2\n",
    "|              |____image11.jpg\n",
    "|              |____image12.jpg\n",
    "|              ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"/tmp/data/beans_disease.zip\" #@param {type:\"string\"}\n",
    "num_epochs = 8 # Número de épocas.\n",
    "trials = 5 # Número de tentativas para o algoritmo de busca por arquiteturas e hyperparametros.\n",
    "batch_size = 8 # Tamanho do lote de imagens\n",
    "target_size = (256, 256) # Tamanho das imagens de entrada da rede\n",
    "\n",
    "'''\n",
    "[OPCIONAIS]\n",
    "Aumentações são técnicas que comprovadamente ajudam \n",
    "a melhorar o desempenho e generalização dos modelos.\n",
    "Essas técnicas serão utilizadas apenas nos conjuntos de treino e validação. \n",
    "Não utilizadas no conjunto de teste.\n",
    "Possibilidades de aumentações para utilizar no dataset estão listadas abaixo:\n",
    "\n",
    "Mais explicações sobre cada aumentação podem ser encontradas no link:\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "'''\n",
    "\n",
    "brightness_range = None # Tupla ou lista de dois float. Range for picking a brightness shift value from.\n",
    "channel_shift_range = 0.0 # Float. Range for random channel shifts.\n",
    "cval = 0.0 # Float or Int. Value used for points outside the boundaries when fill_mode = \"constant\".\n",
    "data_format = None # Formato dos dados da imagem, pode ser \"channels_first\" ou \"channels_last\". Padrão é \"channels_last\".\n",
    "dtype = 'float32' # Dtype para usar nos arrays gerados.\n",
    "featurewise_center = False # Boolean. Set input mean to 0 over the dataset, feature-wise.\n",
    "featurewise_std_normalization = False # Boolean. Divide entradas pelo desvio padrão (std) do dataset em recursos, feature-wise.\n",
    "fill_mode = 'nearest' # Opções: {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Padrão é 'nearest'.\n",
    "horizontal_flip = False # Boolean. Aplica inversão horizontal nas entragas aleatoriamente.\n",
    "preprocessing_function = None # Funções que serão aplicadas em cada entrada. A função irá rodar após a imagem ser aumentada e redimensionada.\n",
    "rescale = 1./255 # Fator de re-escala. Padrão é None. Se None ou 0, nenhuma re-escala serã aplicada, caso contrário cada data será multiplicado pelo valor especificado.\n",
    "rotation_range = 0 # Int. Degree range for random rotations.\n",
    "samplewise_center = False # Boolean. Define cada média de amostra para 0.\n",
    "samplewise_std_normalization = False # Boolean. Divide cada entrada por seu desvio padrão.\n",
    "shear_range = 0.0 # Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees) \n",
    "validation_split = 0.0 # Float. Fraction of images reserved for validation (strictly between 0 and 1).\n",
    "vertical_flip = False # Boolean.  Aplica inversão vertical nas entragas aleatoriamente.\n",
    "zca_whitening = False # Boolean. Apply ZCA whitening.\n",
    "zca_epsilon = 1e-06 # epsilon for ZCA whitening. Default is 1e-6.\n",
    "zoom_range = 0.0 # Float or [lower, upper]. Range for random zoom.\n",
    "'''\n",
    "width_shift_range or height_shift_range: Float, 1-D array-like or int. \n",
    "- Float: fraction of total width (height) if < 1, or pixels if >= 1. \n",
    "- 1-D array-like: random elements from the array. \n",
    "- int: integer number of pixels from interval (-shift_range, +shift_range)\n",
    "'''\n",
    "height_shift_range = 0.0\n",
    "width_shift_range = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: autokeras==1.0.12 in /opt/conda/lib/python3.7/site-packages (1.0.12)\n",
      "Requirement already satisfied: keras-tuner>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from autokeras==1.0.12) (1.0.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from autokeras==1.0.12) (0.22.2.post1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from autokeras==1.0.12) (20.8)\n",
      "Requirement already satisfied: tensorflow>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from autokeras==1.0.12) (2.3.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from autokeras==1.0.12) (1.2.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras==1.0.12) (2.25.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras==1.0.12) (0.4.4)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras==1.0.12) (0.18.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras==1.0.12) (1.4.1)\n",
      "Requirement already satisfied: terminaltables in /opt/conda/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras==1.0.12) (3.1.0)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras==1.0.12) (0.8.7)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras==1.0.12) (4.41.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras==1.0.12) (1.18.5)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (2.4.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (3.14.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (3.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (0.36.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (0.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (1.35.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras==1.0.12) (1.6.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (0.4.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (1.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (3.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (49.6.0.post20210108)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (4.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner>=1.0.2->autokeras==1.0.12) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner>=1.0.2->autokeras==1.0.12) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner>=1.0.2->autokeras==1.0.12) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner>=1.0.2->autokeras==1.0.12) (1.26.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.12) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->autokeras==1.0.12) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->autokeras==1.0.12) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->autokeras==1.0.12) (2020.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->autokeras==1.0.12) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install autokeras==1.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "root_folder_name = dataset.split(\"/\")[-1].split(\".\")[0]\n",
    "root_folder = os.path.join(\"/tmp/data\", root_folder_name)\n",
    "with zipfile.ZipFile(dataset, 'r') as zip_ref:\n",
    "    zip_ref.extractall(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do iterador de dados para a fase de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Found 1034 files belonging to 3 classes.\n",
      "Found 133 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(root_folder, 'train'),\n",
    "    labels='inferred', label_mode='int',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(root_folder, 'val'),\n",
    "    labels='inferred', label_mode='int',\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angular_leaf_spot', 'bean_rust', 'healthy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciação do [autokeras](https://autokeras.com/tutorial/image_classification/) para Classificação de Imagens e busca pela melhor arquitetura e hyperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "model = ak.ImageClassifier(\n",
    "    num_classes=len(train_data.class_names),\n",
    "    max_trials=trials,\n",
    "    metrics=\"accuracy\",\n",
    "    objective=\"val_loss\",\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [01h 23m 55s]\n",
      "val_loss: 1.1015214920043945\n",
      "\n",
      "Best val_loss So Far: 1.0977067947387695\n",
      "Total elapsed time: 01h 45m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/2\n",
      "130/130 [==============================] - 486s 4s/step - loss: 2.5756 - accuracy: 0.3240 - val_loss: 1.0994 - val_accuracy: 0.3158\n",
      "Epoch 2/2\n",
      "130/130 [==============================] - 497s 4s/step - loss: 1.0997 - accuracy: 0.3191 - val_loss: 1.0984 - val_accuracy: 0.3459\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportação do melhor modelo e exposição da sua configuração de camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "cast_to_float32 (CastToFloat (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 256, 256, 3)       7         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 252, 252, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1016064)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1016064)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 3048195   \n",
      "_________________________________________________________________\n",
      "classification_head_1 (Softm (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,067,594\n",
      "Trainable params: 3,067,587\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_exported = model.export_model()\n",
    "model_exported.summary()\n",
    "model_path = \"/tmp/data/model_weights.h5\"\n",
    "model_exported.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação dos dataloaders para última fase de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1034 images belonging to 3 classes.\n",
      "Found 133 images belonging to 3 classes.\n",
      "Found 128 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "    brightness_range = brightness_range,\n",
    "    channel_shift_range = channel_shift_range,\n",
    "    cval = cval,\n",
    "    data_format = data_format,\n",
    "    dtype = dtype,\n",
    "    featurewise_center = featurewise_center,\n",
    "    featurewise_std_normalization = featurewise_std_normalization,\n",
    "    fill_mode = fill_mode,\n",
    "    horizontal_flip = horizontal_flip,\n",
    "    preprocessing_function = preprocessing_function,\n",
    "    rescale = rescale,\n",
    "    rotation_range = rotation_range,\n",
    "    samplewise_center = False,\n",
    "    samplewise_std_normalization = samplewise_std_normalization,\n",
    "    shear_range = shear_range,\n",
    "    validation_split = validation_split,\n",
    "    vertical_flip = vertical_flip,\n",
    "    zca_whitening = zca_whitening,\n",
    "    zca_epsilon = zca_epsilon,\n",
    "    zoom_range = zoom_range,\n",
    "    height_shift_range = height_shift_range,\n",
    "    width_shift_range = width_shift_range\n",
    ")\n",
    "\n",
    "train_generator = image_generator.flow_from_directory(\n",
    "    os.path.join(root_folder, 'train'),\n",
    "    batch_size=batch_size,\n",
    "    target_size=target_size)\n",
    "\n",
    "validation_generator = image_generator.flow_from_directory(\n",
    "    os.path.join(root_folder, 'val'),\n",
    "    batch_size=batch_size,\n",
    "    target_size=target_size)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=rescale,\n",
    "    dtype=dtype)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(root_folder, 'test'),\n",
    "    batch_size=batch_size,\n",
    "    target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino do melhor modelo encontrado na busca utilizando Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "130/130 [==============================] - 450s 3s/step - loss: 1.0989 - accuracy: 0.3221 - val_loss: 1.0986 - val_accuracy: 0.3308\n",
      "Epoch 2/2\n",
      "130/130 [==============================] - 439s 3s/step - loss: 1.0988 - accuracy: 0.2979 - val_loss: 1.0986 - val_accuracy: 0.3383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3af6872f50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_path)\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=num_epochs,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do melhor modelo no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 8s 529ms/step - loss: 1.0986 - accuracy: 0.3359\n",
      "Loss, Acc: 1.098594069480896 0.3359375\n"
     ]
    }
   ],
   "source": [
    "# evaluate the best model\n",
    "loss, acc = model.evaluate(x=test_generator, verbose=True)\n",
    "print(\"Loss: {0} / Acc: {1}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(x=test_generator)\n",
    "preds = []\n",
    "for prediction in predictions:\n",
    "    indx = np.argmax(prediction)\n",
    "    preds.append([indx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração do relatório de classificação e da matrix de confusão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "report = classification_report(test_generator.classes, preds, target_names=test_generator.class_indices.keys())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "angular_leaf_spot       0.00      0.00      0.00        43\n",
      "        bean_rust       0.34      1.00      0.50        43\n",
      "          healthy       0.00      0.00      0.00        42\n",
      "\n",
      "         accuracy                           0.34       128\n",
      "        macro avg       0.11      0.33      0.17       128\n",
      "     weighted avg       0.11      0.34      0.17       128\n",
      "\n",
      "### Confusion matrix:###\n",
      " [[ 0 43  0]\n",
      " [ 0 43  0]\n",
      " [ 0 42  0]]\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_generator.classes, preds)\n",
    "print(\"### Confusion matrix:###\\n\", c_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva resultados da tarefa\n",
    "\n",
    "A plataforma guarda o conteúdo de `/tmp/data/` para as tarefas subsequentes.<br>\n",
    "Use essa pasta para salvar modelos, metadados e outros resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "artifacts = {\n",
    "    \"model_path\": model_path,\n",
    "}\n",
    "\n",
    "dump(artifacts, \"/tmp/data/model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
    "task_id": "b7a312ca-5d66-4d18-a313-fd247933ed50",
    "experiment_id": "abd0eb69-15e2-429c-8196-3dac7c7fc42b",
    "operator_id": "c84fe669-c8d8-4a57-98a3-f15aa68ad22d"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
