{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation - Experimento\n",
    "\n",
    "Data Augmentation é uma estratégia bastante utilizada para impulsionar treinamento de modelos. Se baseando em diversas transformações nos dados, as abordagens de Data Augmentation conseguem multiplicar os seus dados mantendo os mesmos rótulos. Exemplos dessas transformações em dados de imagens são rotações, translações, mudança de coloração, e etc.\n",
    "\n",
    "A implementação desse componente foi feita utilizando a biblioteca [torchvision](https://pytorch.org/vision/stable/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de Classe para Predições em Tempo Real\n",
    "\n",
    "A tarefa de implantação cria um serviço REST para predições em tempo-real.<br>\n",
    "Para isso você deve criar uma classe `Model` que implementa o método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Model.py\n",
    "from typing import List, Iterable, Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms as T\n",
    "import joblib\n",
    "from PIL import Image\n",
    "import io\n",
    "from io import StringIO\n",
    "\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loaded = False\n",
    "        \n",
    "    def load(self):\n",
    "        # Carrega artefatos: estimador, etc\n",
    "        artifacts = joblib.load(\"/tmp/data/data_augmentation.joblib\")\n",
    "        self.artifacts = artifacts[\"data_augmentation_parameters\"]\n",
    "        \n",
    "        self.parameters = [ self.artifacts[\"augmentation_rate\"],\n",
    "                            self.artifacts[\"horizontal_flip\"],\n",
    "                            self.artifacts[\"vertical_flip\"],\n",
    "                            self.artifacts[\"crop\"],\n",
    "                            self.artifacts[\"color_jitter\"],\n",
    "                            self.artifacts[\"perspective\"],\n",
    "                            self.artifacts[\"rotate\"] ]\n",
    "\n",
    "        self.augmentation_rate = self.parameters[0]\n",
    "        \n",
    "        # Load Model\n",
    "\n",
    "        self.jitter = T.ColorJitter(brightness=.5, hue=.3)\n",
    "        self.perspective_transformer = T.RandomPerspective(distortion_scale=0.6, p=1.0)\n",
    "        self.rotater = T.RandomRotation(degrees=(0, 180))\n",
    "        self.hflip = T.RandomHorizontalFlip()\n",
    "        self.vflip = T.RandomVerticalFlip() \n",
    "        \n",
    "        #self.transformations = [ self.jitter, self.perspective_transformer, self.rotater, self.crop, self.hflip, self.vflip ]\n",
    "        \n",
    "        self.loaded = True\n",
    "        \n",
    "    def predict(self, X, feature_names, meta=None):\n",
    "\n",
    "        if not self.loaded:\n",
    "            self.load()\n",
    "            \n",
    "        # Check if data is a bytes\n",
    "        if isinstance(X, bytes):\n",
    "            im_bytes = X # Get image bytes\n",
    "        \n",
    "        # If not, should be a list or ndarray\n",
    "        else:\n",
    "            # Garantee is a ndarray\n",
    "            X = np.array(X)\n",
    "            \n",
    "            # Seek for extra dimension\n",
    "            if len(X.shape) == 2:\n",
    "                im_bytes = X[0,0] # Get image bytes\n",
    "            \n",
    "            else:\n",
    "                im_bytes = X[0] # Get image bytes\n",
    "        \n",
    "        # Preprocess img bytes to img_arr\n",
    "        im_arr = np.frombuffer(im_bytes, dtype=np.uint8)\n",
    "        img = cv2.imdecode(im_arr, flags=cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img) # convert to PIL image\n",
    "\n",
    "        width, height = img.size\n",
    "        crop_size = (int(width * 0.8),int(height * 0.8))  \n",
    "        self.crop = T.RandomCrop(crop_size)\n",
    "\n",
    "        transformed_images = []\n",
    "        if self.parameters[1]:\n",
    "            transformed_images += [self.hflip(img) for _ in range(self.augmentation_rate) ]\n",
    "        if self.parameters[2]:\n",
    "            transformed_images += [self.vflip(img) for _ in range(self.augmentation_rate) ]\n",
    "        if self.parameters[3]:\n",
    "            transformed_images += [self.crop(img) for _ in range(self.augmentation_rate) ]\n",
    "        if self.parameters[4]:\n",
    "            transformed_images += [self.jitter(img) for _ in range(self.augmentation_rate) ]\n",
    "        if self.parameters[5]:\n",
    "            transformed_images += [self.perspective_transformer(img) for _ in range(self.augmentation_rate) ]\n",
    "        if self.parameters[6]:\n",
    "            transformed_images += [self.rotater(img) for _ in range(self.augmentation_rate) ]\n",
    "                \n",
    "        # Compile results        \n",
    "        results = []\n",
    "        for transf_img in transformed_images:\n",
    "            buff = io.BytesIO()\n",
    "            transf_img.save(buff, format=\"JPEG\")\n",
    "            results.append(buff.getvalue().decode(\"latin1\"))\n",
    "             \n",
    "        return results"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "f795343b-5a9d-46a0-8336-41d5079e49a8",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "operator_id": "db47ff60-929f-4dad-ad91-efbb373367cd",
  "task_id": "e7e66db7-1bef-4f64-8c41-834dc112d518"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
